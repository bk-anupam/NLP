{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "from nltk.stem.snowball import SnowballStemmer\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from sklearn.model_selection import cross_validate\r\n",
    "\r\n",
    "df_train = pd.read_csv('./data/train.csv')\r\n",
    "df_test = pd.read_csv('./data/test.csv')\r\n",
    "print(f\"Rows in train.csv = {len(df_train)}\")\r\n",
    "print(f\"Rows in test.csv = {len(df_test)}\")\r\n",
    "pd.set_option('display.max_colwidth', None)\r\n",
    "df_train.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Rows in train.csv = 7613\n",
      "Rows in test.csv = 3263\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation orders in California</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location  \\\n",
       "0   1     NaN      NaN   \n",
       "1   4     NaN      NaN   \n",
       "2   5     NaN      NaN   \n",
       "3   6     NaN      NaN   \n",
       "4   7     NaN      NaN   \n",
       "\n",
       "                                                                                                                                    text  \\\n",
       "0                                                                  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all   \n",
       "1                                                                                                 Forest fire near La Ronge Sask. Canada   \n",
       "2  All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected   \n",
       "3                                                                      13,000 people receive #wildfires evacuation orders in California    \n",
       "4                                               Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school    \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-24T11:29:35.989692Z",
     "iopub.status.busy": "2021-09-24T11:29:35.988494Z",
     "iopub.status.idle": "2021-09-24T11:29:37.721542Z",
     "shell.execute_reply": "2021-09-24T11:29:37.720795Z",
     "shell.execute_reply.started": "2021-09-24T11:25:43.524893Z"
    },
    "papermill": {
     "duration": 1.765907,
     "end_time": "2021-09-24T11:29:37.721745",
     "exception": false,
     "start_time": "2021-09-24T11:29:35.955838",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "df_train_pos = df_train[df_train.target == 1]\r\n",
    "df_train_neg = df_train[df_train.target == 0]\r\n",
    "print(f\"No. of positive training examples = {len(df_train_pos)}\")\r\n",
    "print(f\"No. of negative training examples = {len(df_train_neg)}\")\r\n",
    "train_keywords_unique = df_train.keyword.unique()\r\n",
    "print(f\"No. of unique keywords = {len(train_keywords_unique)}\")\r\n",
    "df_train_notnull_keywords = df_train[~df_train.keyword.isnull()]\r\n",
    "print(f\"No of train examples with keyword not null = {len(df_train_notnull_keywords)}\")\r\n",
    "df_train_notnull_keywords.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No. of positive training examples = 3271\n",
      "No. of negative training examples = 4342\n",
      "No. of unique keywords = 222\n",
      "No of train examples with keyword not null = 7552\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>48</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>@bbcmtd Wholesale Markets ablaze http://t.co/lHYXEOHY6C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>49</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Est. September 2012 - Bristol</td>\n",
       "      <td>We always try to bring the heavy. #metal #RT http://t.co/YAo1e0xngw</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>50</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>#AFRICANBAZE: Breaking news:Nigeria flag set ablaze in Aba. http://t.co/2nndBGwyEi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>52</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Crying out for more! Set me ablaze</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>53</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>London, UK</td>\n",
       "      <td>On plus side LOOK AT THE SKY LAST NIGHT IT WAS ABLAZE http://t.co/qqsmshaJ3N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id keyword                       location  \\\n",
       "31  48  ablaze                     Birmingham   \n",
       "32  49  ablaze  Est. September 2012 - Bristol   \n",
       "33  50  ablaze                         AFRICA   \n",
       "34  52  ablaze               Philadelphia, PA   \n",
       "35  53  ablaze                     London, UK   \n",
       "\n",
       "                                                                                  text  \\\n",
       "31                             @bbcmtd Wholesale Markets ablaze http://t.co/lHYXEOHY6C   \n",
       "32                 We always try to bring the heavy. #metal #RT http://t.co/YAo1e0xngw   \n",
       "33  #AFRICANBAZE: Breaking news:Nigeria flag set ablaze in Aba. http://t.co/2nndBGwyEi   \n",
       "34                                                  Crying out for more! Set me ablaze   \n",
       "35        On plus side LOOK AT THE SKY LAST NIGHT IT WAS ABLAZE http://t.co/qqsmshaJ3N   \n",
       "\n",
       "    target  \n",
       "31       1  \n",
       "32       0  \n",
       "33       1  \n",
       "34       0  \n",
       "35       0  "
      ]
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-24T11:29:37.787808Z",
     "iopub.status.busy": "2021-09-24T11:29:37.787078Z",
     "iopub.status.idle": "2021-09-24T11:29:37.822364Z",
     "shell.execute_reply": "2021-09-24T11:29:37.821464Z",
     "shell.execute_reply.started": "2021-09-24T11:25:45.378728Z"
    },
    "papermill": {
     "duration": 0.071705,
     "end_time": "2021-09-24T11:29:37.822571",
     "exception": false,
     "start_time": "2021-09-24T11:29:37.750866",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "df_test.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, stay safe everyone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location  \\\n",
       "0   0     NaN      NaN   \n",
       "1   2     NaN      NaN   \n",
       "2   3     NaN      NaN   \n",
       "3   9     NaN      NaN   \n",
       "4  11     NaN      NaN   \n",
       "\n",
       "                                                                                               text  \n",
       "0                                                                Just happened a terrible car crash  \n",
       "1                                  Heard about #earthquake is different cities, stay safe everyone.  \n",
       "2  there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all  \n",
       "3                                                          Apocalypse lighting. #Spokane #wildfires  \n",
       "4                                                     Typhoon Soudelor kills 28 in China and Taiwan  "
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-24T11:29:37.892195Z",
     "iopub.status.busy": "2021-09-24T11:29:37.891301Z",
     "iopub.status.idle": "2021-09-24T11:29:37.894938Z",
     "shell.execute_reply": "2021-09-24T11:29:37.895466Z",
     "shell.execute_reply.started": "2021-09-24T11:25:45.423964Z"
    },
    "papermill": {
     "duration": 0.043933,
     "end_time": "2021-09-24T11:29:37.895658",
     "exception": false,
     "start_time": "2021-09-24T11:29:37.851725",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preprocess the tweets "
   ],
   "metadata": {
    "papermill": {
     "duration": 0.029155,
     "end_time": "2021-09-24T11:29:37.954056",
     "exception": false,
     "start_time": "2021-09-24T11:29:37.924901",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "from nltk.stem import WordNetLemmatizer\r\n",
    "from nltk.tokenize import TweetTokenizer\r\n",
    "import string\r\n",
    "import re\r\n",
    "\r\n",
    "punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~`\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\r\n",
    "def clean_special_chars(text, punct):\r\n",
    "    for p in punct:\r\n",
    "        text = text.replace(p, ' ')\r\n",
    "    return text\r\n",
    "\r\n",
    "def process_tweet(df, text, keyword):\r\n",
    "    lemmatizer = WordNetLemmatizer()    \r\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)    \r\n",
    "    processed_text = []\r\n",
    "    stop = stopwords.words(\"english\")\r\n",
    "    for tweet, keyword in zip(df[text], df[keyword]):\r\n",
    "        tweets_clean = []        \r\n",
    "        # remove stock market tickers like $GE\r\n",
    "        #tweet = tweet + \" \" + keyword\r\n",
    "        tweet = re.sub(r'\\$\\w*', '', tweet)\r\n",
    "        # remove old style retweet text \"RT\"\r\n",
    "        tweet = re.sub(r'^RT[\\s]+', '', tweet)\r\n",
    "        # remove hyperlinks\r\n",
    "        tweet = re.sub(r'http\\S+', '', tweet)\r\n",
    "        # remove hashtags\r\n",
    "        # only removing the hash #, @, ... sign from the word\r\n",
    "        tweet = re.sub(r'\\.{3}|@|#', '', tweet)    \r\n",
    "        tweet = clean_special_chars(tweet, punct)\r\n",
    "        # remove junk characters which don't have an ascii code\r\n",
    "        tweet = tweet.encode(\"ascii\", \"ignore\").decode(\"utf-8\", \"ignore\")\r\n",
    "        # tokenize tweets        \r\n",
    "        tweet_tokens = tokenizer.tokenize(tweet)\r\n",
    "        for word in tweet_tokens:\r\n",
    "            # remove stopwords and punctuation\r\n",
    "            #if (word.isalpha() and len(word) > 2 #and word not in stop \r\n",
    "            #    and word not in string.punctuation):\r\n",
    "                #stem_word = stemmer.stem(word)  # stemming word            \r\n",
    "                #lem_word = lemmatizer.lemmatize(word)\r\n",
    "                #tweets_clean.append(lem_word) \r\n",
    "                tweets_clean.append(word)\r\n",
    "        processed_text.append(\" \".join(tweets_clean))        \r\n",
    "    df['processed_text'] = np.array(processed_text)"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-24T11:29:43.429967Z",
     "iopub.status.busy": "2021-09-24T11:29:43.429217Z",
     "iopub.status.idle": "2021-09-24T11:29:43.432488Z",
     "shell.execute_reply": "2021-09-24T11:29:43.431898Z",
     "shell.execute_reply.started": "2021-09-24T11:25:50.679824Z"
    },
    "papermill": {
     "duration": 0.044876,
     "end_time": "2021-09-24T11:29:43.432656",
     "exception": false,
     "start_time": "2021-09-24T11:29:43.387780",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "df_train[\"keyword\"] = df_train[\"keyword\"].fillna(\"no_keyword\")\r\n",
    "df_test[\"keyword\"] = df_test[\"keyword\"].fillna(\"no_keyword\")\r\n",
    "process_tweet(df_train, 'text', \"keyword\")\r\n",
    "process_tweet(df_test, 'text', \"keyword\")\r\n",
    "df_train[\"prcsd_tweet_len\"] = df_train[\"processed_text\"].apply(lambda row: len(row.split()))\r\n",
    "df_test[\"prcsd_tweet_len\"] = df_test[\"processed_text\"].apply(lambda row: len(row.split()))"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-24T11:29:43.494947Z",
     "iopub.status.busy": "2021-09-24T11:29:43.493949Z",
     "iopub.status.idle": "2021-09-24T11:29:48.131903Z",
     "shell.execute_reply": "2021-09-24T11:29:48.132422Z",
     "shell.execute_reply.started": "2021-09-24T11:25:50.692578Z"
    },
    "papermill": {
     "duration": 4.670808,
     "end_time": "2021-09-24T11:29:48.132640",
     "exception": false,
     "start_time": "2021-09-24T11:29:43.461832",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "df_train[\"prcsd_tweet_len\"].mean()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "14.597136477078681"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "df_train.iloc[50:52, :]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>prcsd_tweet_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>73</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Sheffield Township, Ohio</td>\n",
       "      <td>Deputies: Man shot before Brighton home set ablaze http://t.co/gWNRhMSO8k</td>\n",
       "      <td>1</td>\n",
       "      <td>deputies man shot before brighton home set ablaze</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>74</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>India</td>\n",
       "      <td>Man wife get six years jail for setting ablaze niece\\nhttp://t.co/eV1ahOUCZA</td>\n",
       "      <td>1</td>\n",
       "      <td>man wife get six years jail for setting ablaze niece</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id keyword                  location  \\\n",
       "50  73  ablaze  Sheffield Township, Ohio   \n",
       "51  74  ablaze                     India   \n",
       "\n",
       "                                                                            text  \\\n",
       "50     Deputies: Man shot before Brighton home set ablaze http://t.co/gWNRhMSO8k   \n",
       "51  Man wife get six years jail for setting ablaze niece\\nhttp://t.co/eV1ahOUCZA   \n",
       "\n",
       "    target                                        processed_text  \\\n",
       "50       1     deputies man shot before brighton home set ablaze   \n",
       "51       1  man wife get six years jail for setting ablaze niece   \n",
       "\n",
       "    prcsd_tweet_len  \n",
       "50                8  \n",
       "51               10  "
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-24T11:29:48.195063Z",
     "iopub.status.busy": "2021-09-24T11:29:48.194413Z",
     "iopub.status.idle": "2021-09-24T11:29:48.207920Z",
     "shell.execute_reply": "2021-09-24T11:29:48.208468Z",
     "shell.execute_reply.started": "2021-09-24T11:25:55.413845Z"
    },
    "papermill": {
     "duration": 0.046078,
     "end_time": "2021-09-24T11:29:48.208659",
     "exception": false,
     "start_time": "2021-09-24T11:29:48.162581",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "\r\n",
    "df_test.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>prcsd_tweet_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>just happened a terrible car crash</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, stay safe everyone.</td>\n",
       "      <td>heard about earthquake is different cities stay safe everyone</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all</td>\n",
       "      <td>there is a forest fire at spot pond geese are fleeing across the street i cannot save them all</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>apocalypse lighting spokane wildfires</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>typhoon soudelor kills 28 in china and taiwan</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     keyword location  \\\n",
       "0   0  no_keyword      NaN   \n",
       "1   2  no_keyword      NaN   \n",
       "2   3  no_keyword      NaN   \n",
       "3   9  no_keyword      NaN   \n",
       "4  11  no_keyword      NaN   \n",
       "\n",
       "                                                                                               text  \\\n",
       "0                                                                Just happened a terrible car crash   \n",
       "1                                  Heard about #earthquake is different cities, stay safe everyone.   \n",
       "2  there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all   \n",
       "3                                                          Apocalypse lighting. #Spokane #wildfires   \n",
       "4                                                     Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "\n",
       "                                                                                   processed_text  \\\n",
       "0                                                              just happened a terrible car crash   \n",
       "1                                   heard about earthquake is different cities stay safe everyone   \n",
       "2  there is a forest fire at spot pond geese are fleeing across the street i cannot save them all   \n",
       "3                                                           apocalypse lighting spokane wildfires   \n",
       "4                                                   typhoon soudelor kills 28 in china and taiwan   \n",
       "\n",
       "   prcsd_tweet_len  \n",
       "0                6  \n",
       "1                9  \n",
       "2               19  \n",
       "3                4  \n",
       "4                8  "
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-24T11:29:48.271874Z",
     "iopub.status.busy": "2021-09-24T11:29:48.271196Z",
     "iopub.status.idle": "2021-09-24T11:29:48.285535Z",
     "shell.execute_reply": "2021-09-24T11:29:48.284912Z",
     "shell.execute_reply.started": "2021-09-24T11:25:55.431885Z"
    },
    "papermill": {
     "duration": 0.046942,
     "end_time": "2021-09-24T11:29:48.285685",
     "exception": false,
     "start_time": "2021-09-24T11:29:48.238743",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Let us try some deep learning techniques now"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "def get_word_embedding_dict(embedding_file_path):\r\n",
    "    embedding_dict = {}\r\n",
    "    with open(embedding_file_path, \"r\") as f:\r\n",
    "        # https://stackoverflow.com/questions/8009882/how-to-read-a-large-file-line-by-line\r\n",
    "        for line in f:\r\n",
    "            values = line.split()\r\n",
    "            word = values[0]\r\n",
    "            word_vec = np.asarray(values[1:], \"float32\")\r\n",
    "            embedding_dict[word] = word_vec\r\n",
    "    return embedding_dict        \r\n",
    "\r\n",
    "#glove_embedding_dict = get_word_embedding_dict(\"../../../glove.twitter.27B/glove.twitter.27B.200d.txt\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "import torchtext\r\n",
    "\r\n",
    "glove_emb = torchtext.vocab.GloVe(name=\"twitter.27B\", dim=200)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "# build tweets vocab from training data\r\n",
    "\r\n",
    "from torchtext.vocab import build_vocab_from_iterator\r\n",
    "\r\n",
    "def yield_tokens(df):\r\n",
    "    for index, row in df.iterrows():\r\n",
    "        yield row[\"processed_text\"].split()\r\n",
    "    \r\n",
    "tweet_vocab = build_vocab_from_iterator(yield_tokens(df_train), specials=[\"<unk>\", \"<pad>\"])    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "# For the problem specific vocab, get the embedding vectors from the pre-trained embedding\r\n",
    "# for each word in vocab and return a matrix of shape vocab_size, embedding_dim. This matrix\r\n",
    "# will be the pretrained embedding weight matrix which we will use to create the embedding layer\r\n",
    "def get_vocab_pt_emb_matrix(text_vocab, emb):\r\n",
    "    embedding_matrix = []\r\n",
    "    for token in text_vocab.get_itos():\r\n",
    "        embedding_matrix.append(emb[token])\r\n",
    "    return torch.stack(embedding_matrix)\r\n",
    "\r\n",
    "pt_emb_weights = get_vocab_pt_emb_matrix(tweet_vocab, glove_emb)\r\n",
    "pt_emb_layer = nn.Embedding.from_pretrained(pt_emb_weights)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "# [(index, token) for index, token in enumerate(glove_emb.itos) if token == \"<unk>\"]\r\n",
    "#pt_emb_layer(torch.LongTensor([1]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\r\n",
    "\r\n",
    "df_train[\"vectorized_tweet\"] = df_train[\"processed_text\"].apply(\r\n",
    "    lambda row:torch.LongTensor(tweet_vocab.lookup_indices(row.split()))\r\n",
    "    )\r\n",
    "\r\n",
    "#x_seq = df_train[\"vectorized_tweet\"].values.tolist()\r\n",
    "# the index for 'pad' token in tweet_vocab is 1.\r\n",
    "#x_padded_seq = pad_sequence(x_seq, batch_first=True, padding_value=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "from torch.utils.data import Dataset, DataLoader\r\n",
    "\r\n",
    "class VectorizedTweetDataSet(Dataset):\r\n",
    "    def __init__(self, tweet_vecs, labels):\r\n",
    "        self.tweet_vecs = tweet_vecs\r\n",
    "        self.labels = labels\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.labels)\r\n",
    "\r\n",
    "    def __getitem__(self, idx):\r\n",
    "        tweet_vec = self.tweet_vecs[idx]\r\n",
    "        label = self.labels[idx]\r\n",
    "        tweet_len = len(tweet_vec)\r\n",
    "        return (tweet_vec, label)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "# If the goal is to train with mini-batches, one needs to pad the sequences in each batch. \r\n",
    "# In other words, given a mini-batch of size N, if the length of the largest sequence is L, \r\n",
    "# one needs to pad every sequence with a length of smaller than L with zeros and make their \r\n",
    "# lengths equal to L. Moreover, it is important that the sequences in the batch are in the \r\n",
    "# descending order.\r\n",
    "def pad_collate(batch):\r\n",
    "    # Each element in the batch is a tuple (data, label)\r\n",
    "    # sort the batch (based on tweet word count) in descending order\r\n",
    "    sorted_batch = sorted(batch, key=lambda x:x[0].shape[0], reverse=True)\r\n",
    "    sequences = [x[0] for x in sorted_batch]\r\n",
    "    sequences_padded = pad_sequence(sequences, batch_first=True, padding_value=0)\r\n",
    "    # Also need to store the length of each sequence.This is later needed in order to unpad \r\n",
    "    # the sequences\r\n",
    "    seq_len = torch.Tensor([len(x) for x in sequences])\r\n",
    "    labels = torch.Tensor([x[1] for x in sorted_batch])\r\n",
    "    return sequences_padded, seq_len, labels\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torch.nn import functional as F\r\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\r\n",
    "\r\n",
    "class DisasterModel(nn.Module):\r\n",
    "    \"\"\"The RNN model.\"\"\"\r\n",
    "    def __init__(self, vocab_size, num_layers, is_bidirect, emb_dim, hidden_dim, out_dim, \r\n",
    "                pt_emb_weights, emb_wt_update=False, drop_prob=0.5, **kwargs):\r\n",
    "        super(DisasterModel, self).__init__(**kwargs)\r\n",
    "        \r\n",
    "        self.vocab_size = vocab_size\r\n",
    "        self.num_layers = num_layers        \r\n",
    "        self.emb_dim = emb_dim\r\n",
    "        self.hidden_dim = hidden_dim        \r\n",
    "        self.output_dim = out_dim        \r\n",
    "        self.is_bidirect = is_bidirect\r\n",
    "        # Embedding layer\r\n",
    "        self.emb_layer = nn.Embedding(self.vocab_size, emb_dim)\r\n",
    "        # copy the vocab specific weights(emb vectors) from pretrained embeddings to model embedding layer\r\n",
    "        self.emb_layer.weight.data.copy_(pt_emb_weights)    \r\n",
    "        # whether to update the pretrained embedding layer weights during model training\r\n",
    "        self.emb_layer.weight.requires_grad = emb_wt_update            \r\n",
    "        # LSTM Layer        \r\n",
    "        self.lstm_layer = nn.LSTM(\r\n",
    "                        input_size=emb_dim, hidden_size=hidden_dim, batch_first=True, \r\n",
    "                        bidirectional=is_bidirect, num_layers=num_layers, dropout=drop_prob\r\n",
    "                        )\r\n",
    "        self.dropout = nn.Dropout(p = drop_prob)                        \r\n",
    "        \r\n",
    "        # If the RNN is bidirectional `num_directions` should be 2, else it should be 1.        \r\n",
    "        if not is_bidirect:\r\n",
    "            self.num_directions = 1\r\n",
    "            # The linear layer is for making predictions \r\n",
    "            # input to linear output layer is of shape num_steps, batch_size, num_hiddens\r\n",
    "            # and output is of shape num_steps, batch_size, vocab_size\r\n",
    "            # Wya is of shape (vocab_size, num_hiddens), a_out is of shape (num_hiddens, 1)\r\n",
    "            # yt_pred = np.dot(Wya, a_out) + b is of shape (vocab_size, 1)\r\n",
    "            # replace 1 with m (batch_size) and add num_steps as the first dimension to have\r\n",
    "            # vectorized form of the output\r\n",
    "            self.linear = nn.Linear(self.hidden_dim, self.output_dim)\r\n",
    "        else:       \r\n",
    "            self.num_directions = 2     \r\n",
    "            self.linear = nn.Linear(self.hidden_dim * self.num_directions * 2, self.output_dim)\r\n",
    "        # The activation layer which converts output to 0 or 1            \r\n",
    "        self.act = nn.Sigmoid()            \r\n",
    "\r\n",
    "    def forward(self, inputs, input_lengths, state):        \r\n",
    "        # inputs is of shape batch_size, num_steps(sequence length which is the length of\r\n",
    "        # longest text sequence). Each row of inputs is 1d LongTensor array of length \r\n",
    "        # num_steps containing word index. Using the embedding layer we want to convert\r\n",
    "        # each word index to its corresponding word vector of dimension emb_dim\r\n",
    "        batch_size = inputs.size(0)\r\n",
    "        num_steps = inputs.size(1)        \r\n",
    "        # embeds is of shape batch_size * num_steps * emb_dim and is the input to lstm layer\r\n",
    "        embeds = self.emb_layer(inputs)        \r\n",
    "        # pack_padded_sequence before feeding into LSTM. This is required so pytorch knows\r\n",
    "        # which elements of the sequence are padded ones and ignore them in computation.\r\n",
    "        # This step is done only after the embedding step\r\n",
    "        embeds_pack = pack_padded_sequence(embeds, input_lengths, batch_first=True)\r\n",
    "        # lstm_out is of shape batch_size * num_steps * hidden_size and contains the output\r\n",
    "        # features (h_t) from the last layer of LSTM for each t\r\n",
    "        # h_n is of shape num_layers * batch_size * hidden_size and contains the final hidden \r\n",
    "        # state for each element in the batch i.e. hidden state at t_end\r\n",
    "        # same for c_n as h_n except that it is the final cell state\r\n",
    "        lstm_out_pack, (h_n, c_n) = self.lstm_layer(embeds_pack)\r\n",
    "        # unpack the output\r\n",
    "        lstm_out, lstm_out_len = pad_packed_sequence(lstm_out_pack, batch_first=True)                \r\n",
    "        if self.is_bidirect:\r\n",
    "            # For a birection LSTM we need to concatenate the last output of each of the\r\n",
    "            # forward (num_steps = 0, dim 2) and backward directions (num_steps = -1, dim 2)\r\n",
    "            #print(f\"lstm_out.shape = {lstm_out.shape}\")\r\n",
    "            lstm_out = torch.cat((lstm_out[:, 0, :], lstm_out[:, -1, :]), dim=1)\r\n",
    "            #print(f\"lstm_out.shape = {lstm_out.shape}\")\r\n",
    "        else:            \r\n",
    "            # The output from lstm layer is the hidden state from last lstm layer with shape\r\n",
    "            # of batch_size * hidden_dim. This can be extracted directly from h_n as below        \r\n",
    "            lstm_out = h_n[-1, :, :]        \r\n",
    "            # or we can extract it from lstm_out and lstm_out_len. lstm_out is of shape\r\n",
    "            # batch_size * num_steps * hidden_dim. Now num_steps is the max sequence length\r\n",
    "            # in the batch, but for items in batch for which sequence length < max sequence length\r\n",
    "            # we need to take the element at lstm_out_len - 1 position in dimension 2 \r\n",
    "            # as elements after it are padded and should be ignored. Thus instead of num_steps\r\n",
    "            # if for each batch item we pick the element at (lstm_out_len - 1) index we get\r\n",
    "            # lstm_out in the shape batch_size * hidden_dim\r\n",
    "        \r\n",
    "        # regularize lstm output by applying dropout\r\n",
    "        out = self.dropout(lstm_out)        \r\n",
    "        # The the output Y of fully connected rnn layer has the shape of \r\n",
    "        # (`num_steps` * `batch_size`, `num_hiddens`). This Y is then fed as input to the \r\n",
    "        # output fully connected linear layer which produces the prediction in the output shape of \r\n",
    "        # (`num_steps` * `batch_size`, `output_dim`).        \r\n",
    "        output = self.linear(out)        \r\n",
    "        # apply sigmoid activation to convert output to probability \r\n",
    "        output = self.act(output)\r\n",
    "        return output, (h_n, c_n)\r\n",
    "\r\n",
    "    def init_state(self, device, batch_size=1):\r\n",
    "        \"\"\" Initialize the hidden state i.e. initialize all the neurons in all the hidden layers \r\n",
    "        to zero\"\"\"\r\n",
    "        if not isinstance(self.lstm_layer, nn.LSTM):\r\n",
    "            # `nn.GRU` takes a tensor as hidden state\r\n",
    "            return torch.zeros((self.num_directions * self.num_layers,\r\n",
    "                                batch_size, self.hidden_dim), device=device)\r\n",
    "        else:\r\n",
    "            # `nn.LSTM` takes a tuple of hidden states (h0, c0). h0 = initial\r\n",
    "            # hidden state for each element in the batch, c0 = initial cell state\r\n",
    "            # for each element in the batch\r\n",
    "            return (torch.zeros((self.num_directions * self.num_layers,\r\n",
    "                                 batch_size, self.hidden_dim), device=device),\r\n",
    "                    torch.zeros((self.num_directions * self.num_layers,\r\n",
    "                                 batch_size, self.hidden_dim), device=device))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "class ModelExecutionEngine:\r\n",
    "    def __init__(self, model, optimizer, device, batch_size, grad_clip):\r\n",
    "        self.model = model\r\n",
    "        self.optimizer = optimizer\r\n",
    "        self.device = device\r\n",
    "        self.batch_size = batch_size\r\n",
    "        self.grad_clip = grad_clip\r\n",
    "\r\n",
    "    @staticmethod\r\n",
    "    def loss_fn(outputs, targets):\r\n",
    "        return nn.BCELoss()(outputs, targets)\r\n",
    "\r\n",
    "    # metric to measure model performance\r\n",
    "    def accuracy(self, outputs, targets):\r\n",
    "        # y_pred is in the range 0 to 1. Convert it to 0 or 1 by rounding\r\n",
    "        outputs_round = torch.round(outputs.squeeze())\r\n",
    "        correct = (outputs_round == targets.squeeze()).float()\r\n",
    "        acc = correct.sum() / len(correct)\r\n",
    "        return acc\r\n",
    "\r\n",
    "    def train_epoch(self, data_loader, init_hidden):\r\n",
    "        self.model.train()\r\n",
    "        loss_epoch = []\r\n",
    "        acc_epoch = [] \r\n",
    "        for inputs, input_lengths, labels in data_loader:\r\n",
    "            # create a new hidden state instance for each minibatch to avoid long gradient chains\r\n",
    "            # involving all previous minibatches of an epoch\r\n",
    "            h = tuple([e.data for e in init_hidden])\r\n",
    "            inputs = inputs.to(self.device)\r\n",
    "            input_lengths = input_lengths.to(self.device)\r\n",
    "            labels = labels.to(self.device)\r\n",
    "            if inputs.shape[0] != self.batch_size:\r\n",
    "                continue        \r\n",
    "            # forward pass on one mini batch\r\n",
    "            output, hidden = self.model(inputs, input_lengths, h)        \r\n",
    "            # compute the loss\r\n",
    "            loss = self.loss_fn(output.squeeze(), labels.float())\r\n",
    "            epoch_acc = self.accuracy(output, labels)        \r\n",
    "            acc_epoch.append(epoch_acc.item())\r\n",
    "            loss_epoch.append(loss.item())\r\n",
    "            # zero out the model param (W and b) gradients before running backprop on this batch \r\n",
    "            # otherwise gradients will keep on aggregating from one batch to next\r\n",
    "            self.optimizer.zero_grad()\r\n",
    "            # run backprop to calculate param gradients (dW and db)\r\n",
    "            loss.backward()\r\n",
    "            # clip the param gradients if they exceed threshold\r\n",
    "            nn.utils.clip_grad_norm_(self.model.parameters(), self.grad_clip)\r\n",
    "            # update the parameters (W and b)\r\n",
    "            self.optimizer.step()            \r\n",
    "        return np.mean(loss_epoch), np.mean(acc_epoch)  \r\n",
    "\r\n",
    "    def evaluate_epoch(self, data_loader, init_hidden):\r\n",
    "        self.model.eval()\r\n",
    "        loss_epoch = []\r\n",
    "        acc_epoch = [] \r\n",
    "        for inputs, input_lengths, labels in data_loader:\r\n",
    "            h = tuple([e.data for e in init_hidden])\r\n",
    "            inputs = inputs.to(self.device)\r\n",
    "            input_lengths = input_lengths.to(self.device)\r\n",
    "            labels = labels.to(self.device)\r\n",
    "            if inputs.shape[0] != self.batch_size:\r\n",
    "                continue                    \r\n",
    "            output, hidden = self.model(inputs, input_lengths, h)        \r\n",
    "            loss = self.loss_fn(output.squeeze(), labels.float())\r\n",
    "            epoch_acc = self.accuracy(output, labels)        \r\n",
    "            acc_epoch.append(epoch_acc.item())\r\n",
    "            loss_epoch.append(loss.item())            \r\n",
    "        return np.mean(loss_epoch), np.mean(acc_epoch)  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "# model constants\r\n",
    "VOCAB_SIZE = len(tweet_vocab)\r\n",
    "EMB_DIM = 200    \r\n",
    "OUT_DIM = 1    \r\n",
    "BATCH_SIZE = 128\r\n",
    "GRAD_CLIP = 5\r\n",
    "NUM_EPOCHS = 20 \r\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')    \r\n",
    "# model hyperparameters\r\n",
    "model_params = {\r\n",
    "    \"hidden_dim\": 141, \r\n",
    "    \"num_layers\": 2, \r\n",
    "    \"is_bidirectional\": False, \r\n",
    "    \"drop_out\": 0.4258,\r\n",
    "    \"learning_rate\": 0.000366\r\n",
    "    }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "def get_exec_time(exec_time_secs):\r\n",
    "    if exec_time_secs < 60:\r\n",
    "        return f\"{round(exec_time_secs, 2)} seconds\"\r\n",
    "    exec_time_rem_sec = exec_time_secs % 60\r\n",
    "    exec_time_min = int((exec_time_secs - exec_time_rem_sec) / 60)\r\n",
    "    return f\"{exec_time_min} min {round(exec_time_rem_sec, 2)} seconds\"\r\n",
    "\r\n",
    "def print_epoch_stats(epoch, train_run_time, train_loss, \r\n",
    "                     train_acc, val_run_time, val_loss, val_acc):\r\n",
    "    print(f\"=======================================================\")\r\n",
    "    print(f\"Epoch {epoch} :\")\r\n",
    "    print(f\"Execution time on training set = {train_run_time} \")\r\n",
    "    print(f\"Training loss = {round(train_loss, 4)}, training accuracy = {round(train_acc, 4)}\")\r\n",
    "    print(f\"Execution time on validation set = {val_run_time} \")\r\n",
    "    print(f\"Validation loss = {round(val_loss, 4)}, validation accuracy = {round(val_acc, 4)}\")        \r\n",
    "    print(f\"=======================================================\")        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "def run_training(train_dl, val_dl, params, save_model=False):\r\n",
    "    val_loss_min = np.Inf   \r\n",
    "    model = DisasterModel(\r\n",
    "                vocab_size = VOCAB_SIZE, \r\n",
    "                emb_dim = EMB_DIM, \r\n",
    "                out_dim = OUT_DIM, \r\n",
    "                pt_emb_weights = pt_emb_weights,\r\n",
    "                num_layers = params[\"num_layers\"], \r\n",
    "                is_bidirect = False,  \r\n",
    "                hidden_dim = params[\"hidden_dim\"], \r\n",
    "                drop_prob = params[\"drop_out\"]                \r\n",
    "                ).to(DEVICE)\r\n",
    "    \r\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params[\"learning_rate\"])\r\n",
    "    init_hidden = model.init_state(device = DEVICE, batch_size = BATCH_SIZE)        \r\n",
    "    mee = ModelExecutionEngine(\r\n",
    "            model=model, \r\n",
    "            optimizer=optimizer, \r\n",
    "            device=DEVICE, \r\n",
    "            batch_size=BATCH_SIZE,\r\n",
    "            grad_clip=GRAD_CLIP\r\n",
    "            )\r\n",
    "    # number of epoch iterations with the validation loss not decreasing \r\n",
    "    # before training process is terminated before completed the total number of epochs             \r\n",
    "    early_stopping_iter = 10            \r\n",
    "    early_stopping_counter = 0     \r\n",
    "    model_exec_stats = {\r\n",
    "        \"all_train_loss\": [],\r\n",
    "        \"all_train_acc\": [],\r\n",
    "        \"all_val_loss\": [],\r\n",
    "        \"all_val_acc\": []\r\n",
    "        }       \r\n",
    "    for epoch in range(NUM_EPOCHS):\r\n",
    "        train_start_time = time.time()\r\n",
    "        train_loss, train_acc = mee.train_epoch(train_dl, init_hidden)\r\n",
    "        model_exec_stats[\"all_train_loss\"].append(train_loss)\r\n",
    "        model_exec_stats[\"all_train_acc\"].append(train_acc)\r\n",
    "        train_end_time = time.time()    \r\n",
    "        train_run_time = get_exec_time(train_end_time - train_start_time)\r\n",
    "        val_start_time = time.time()\r\n",
    "        val_loss, val_acc = mee.evaluate_epoch(val_dl, init_hidden)\r\n",
    "        model_exec_stats[\"all_val_loss\"].append(val_loss)\r\n",
    "        model_exec_stats[\"all_val_acc\"].append(val_acc)\r\n",
    "        val_end_time = time.time()\r\n",
    "        val_run_time = get_exec_time(val_end_time - val_start_time)\r\n",
    "        print_epoch_stats(epoch, train_run_time, train_loss, train_acc,\r\n",
    "                            val_run_time, val_loss, val_acc)  \r\n",
    "        if val_loss < val_loss_min:                        \r\n",
    "            if save_model:\r\n",
    "                print(f\"Validation loss decreased from \" +\r\n",
    "                f\"{round(val_loss_min, 6)} --> {round(val_loss, 6)}. Saving model...\")                \r\n",
    "                torch.save(model, \"best_model.pt\")                \r\n",
    "            val_loss_min = val_loss\r\n",
    "        else:\r\n",
    "            early_stopping_counter += 1\r\n",
    "        if early_stopping_counter > early_stopping_iter:\r\n",
    "            break\r\n",
    "    return val_loss_min, model_exec_stats"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "from torch.utils.data import Subset\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "tweet_ds = VectorizedTweetDataSet(df_train[\"vectorized_tweet\"].values, df_train[\"target\"].values)\r\n",
    "# split the tweet_ds into train and validation datasets with 80:20 ratio\r\n",
    "train_idx, val_idx = train_test_split(list(range(len(tweet_ds))), test_size=0.2, random_state=42)\r\n",
    "train_ds = Subset(tweet_ds, train_idx)\r\n",
    "val_ds = Subset(tweet_ds, val_idx)\r\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=pad_collate)\r\n",
    "val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=pad_collate)\r\n",
    "\r\n",
    "val_loss_min, model_exec_stats = run_training(train_dl, val_dl, params=model_params, save_model=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================================\n",
      "Epoch 0 :\n",
      "Execution time on training set = 17.16 seconds \n",
      "Training loss = 0.632, training accuracy = 0.6368\n",
      "Execution time on validation set = 1.02 seconds \n",
      "Validation loss = 0.5389, validation accuracy = 0.7273\n",
      "=======================================================\n",
      "Validation loss decreased from inf --> 0.53889. Saving model...\n",
      "=======================================================\n",
      "Epoch 1 :\n",
      "Execution time on training set = 18.54 seconds \n",
      "Training loss = 0.4867, training accuracy = 0.7814\n",
      "Execution time on validation set = 0.94 seconds \n",
      "Validation loss = 0.4505, validation accuracy = 0.804\n",
      "=======================================================\n",
      "Validation loss decreased from 0.53889 --> 0.450504. Saving model...\n",
      "=======================================================\n",
      "Epoch 2 :\n",
      "Execution time on training set = 17.32 seconds \n",
      "Training loss = 0.4478, training accuracy = 0.8044\n",
      "Execution time on validation set = 1.06 seconds \n",
      "Validation loss = 0.4434, validation accuracy = 0.8146\n",
      "=======================================================\n",
      "Validation loss decreased from 0.450504 --> 0.443379. Saving model...\n",
      "=======================================================\n",
      "Epoch 3 :\n",
      "Execution time on training set = 15.66 seconds \n",
      "Training loss = 0.4289, training accuracy = 0.811\n",
      "Execution time on validation set = 0.78 seconds \n",
      "Validation loss = 0.4351, validation accuracy = 0.8075\n",
      "=======================================================\n",
      "Validation loss decreased from 0.443379 --> 0.435128. Saving model...\n",
      "=======================================================\n",
      "Epoch 4 :\n",
      "Execution time on training set = 21.08 seconds \n",
      "Training loss = 0.4132, training accuracy = 0.8221\n",
      "Execution time on validation set = 0.87 seconds \n",
      "Validation loss = 0.4246, validation accuracy = 0.8146\n",
      "=======================================================\n",
      "Validation loss decreased from 0.435128 --> 0.424637. Saving model...\n",
      "=======================================================\n",
      "Epoch 5 :\n",
      "Execution time on training set = 16.24 seconds \n",
      "Training loss = 0.4017, training accuracy = 0.8271\n",
      "Execution time on validation set = 0.75 seconds \n",
      "Validation loss = 0.4324, validation accuracy = 0.8175\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 6 :\n",
      "Execution time on training set = 17.67 seconds \n",
      "Training loss = 0.3923, training accuracy = 0.8333\n",
      "Execution time on validation set = 0.82 seconds \n",
      "Validation loss = 0.4341, validation accuracy = 0.8125\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 7 :\n",
      "Execution time on training set = 15.44 seconds \n",
      "Training loss = 0.3868, training accuracy = 0.8361\n",
      "Execution time on validation set = 0.8 seconds \n",
      "Validation loss = 0.4271, validation accuracy = 0.8089\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 8 :\n",
      "Execution time on training set = 17.05 seconds \n",
      "Training loss = 0.3727, training accuracy = 0.8416\n",
      "Execution time on validation set = 0.8 seconds \n",
      "Validation loss = 0.4288, validation accuracy = 0.8224\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 9 :\n",
      "Execution time on training set = 17.18 seconds \n",
      "Training loss = 0.3611, training accuracy = 0.8502\n",
      "Execution time on validation set = 0.98 seconds \n",
      "Validation loss = 0.4237, validation accuracy = 0.8267\n",
      "=======================================================\n",
      "Validation loss decreased from 0.424637 --> 0.423731. Saving model...\n",
      "=======================================================\n",
      "Epoch 10 :\n",
      "Execution time on training set = 17.2 seconds \n",
      "Training loss = 0.3519, training accuracy = 0.8494\n",
      "Execution time on validation set = 0.75 seconds \n",
      "Validation loss = 0.4467, validation accuracy = 0.8139\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 11 :\n",
      "Execution time on training set = 17.65 seconds \n",
      "Training loss = 0.3431, training accuracy = 0.858\n",
      "Execution time on validation set = 1.24 seconds \n",
      "Validation loss = 0.4462, validation accuracy = 0.8217\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 12 :\n",
      "Execution time on training set = 15.07 seconds \n",
      "Training loss = 0.3279, training accuracy = 0.8587\n",
      "Execution time on validation set = 0.77 seconds \n",
      "Validation loss = 0.4269, validation accuracy = 0.8253\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 13 :\n",
      "Execution time on training set = 18.59 seconds \n",
      "Training loss = 0.3176, training accuracy = 0.8733\n",
      "Execution time on validation set = 0.76 seconds \n",
      "Validation loss = 0.4668, validation accuracy = 0.8132\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 14 :\n",
      "Execution time on training set = 15.08 seconds \n",
      "Training loss = 0.304, training accuracy = 0.8747\n",
      "Execution time on validation set = 0.76 seconds \n",
      "Validation loss = 0.4704, validation accuracy = 0.8018\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 15 :\n",
      "Execution time on training set = 14.58 seconds \n",
      "Training loss = 0.2978, training accuracy = 0.8802\n",
      "Execution time on validation set = 0.81 seconds \n",
      "Validation loss = 0.4783, validation accuracy = 0.8175\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 16 :\n",
      "Execution time on training set = 16.45 seconds \n",
      "Training loss = 0.2757, training accuracy = 0.8895\n",
      "Execution time on validation set = 0.92 seconds \n",
      "Validation loss = 0.51, validation accuracy = 0.8068\n",
      "=======================================================\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "all_val_loss = model_exec_stats[\"all_val_loss\"]\r\n",
    "all_val_acc = model_exec_stats[\"all_val_acc\"]\r\n",
    "min_loss_index = np.argmin(all_val_loss)\r\n",
    "print(f\"Min val loss = {all_val_loss[min_loss_index]}, corresponding val accuracy = {all_val_acc[min_loss_index]}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Min val loss = 0.4237306443127719, corresponding val accuracy = 0.8267045454545454\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "def plot_train_val_metrics(ax, train_metric, val_metric, metric_name):\r\n",
    "    ax.plot(train_metric, label = f\"training {metric_name}\")\r\n",
    "    ax.plot(val_metric, label = f\"validation {metric_name}\")\r\n",
    "    ax.set_xlabel(\"epochs\")\r\n",
    "    ax.set_ylabel(metric_name)\r\n",
    "    ax.set_title(f\"{metric_name} vs epochs\")\r\n",
    "    ax.legend()\r\n",
    "    ax.grid()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\r\n",
    "plot_train_val_metrics(ax1, model_exec_stats[\"all_train_loss\"], model_exec_stats[\"all_val_loss\"], \"Loss\")\r\n",
    "plot_train_val_metrics(ax2, model_exec_stats[\"all_train_acc\"], model_exec_stats[\"all_val_acc\"], \"Accuracy\")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "best_model = torch.load(\"best_model.pt\")\r\n",
    "print(best_model)\r\n",
    "tweet_vocab.set_default_index(0)\r\n",
    "df_test[\"vectorized_tweet\"] = df_test[\"processed_text\"].apply(\r\n",
    "    lambda row:torch.LongTensor(tweet_vocab.lookup_indices(row.split()))\r\n",
    "    )\r\n",
    "\r\n",
    "# Do prediction with best performing model on the test set\r\n",
    "def predict(df_test):\r\n",
    "    test_output = []\r\n",
    "    for index, row in df_test.iterrows():    \r\n",
    "        vec_tweet = row[\"vectorized_tweet\"]\r\n",
    "        if len(vec_tweet) == 0:\r\n",
    "            test_output.append(0)\r\n",
    "            continue\r\n",
    "        vec_tweet_len = torch.IntTensor([len(vec_tweet)])\r\n",
    "        vec_tweet = vec_tweet.view(1, -1)    \r\n",
    "        #print(vec_tweet, vec_tweet_len)\r\n",
    "        output, (h_n,c_n) = best_model(vec_tweet, vec_tweet_len, state=None)\r\n",
    "        #print(output)\r\n",
    "        test_output.append(round(output.item()))    \r\n",
    "    return test_output        \r\n",
    "\r\n",
    "test_output = predict(df_test)\r\n",
    "print(len(test_output))\r\n",
    "\r\n",
    "df_submission = pd.read_csv('./data/submission.csv')\r\n",
    "df_submission['target']= test_output\r\n",
    "df_submission.to_csv('my_submission.csv',index=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DisasterModel(\n",
      "  (emb_layer): Embedding(17120, 200)\n",
      "  (lstm_layer): LSTM(200, 141, num_layers=2, batch_first=True, dropout=0.4258)\n",
      "  (dropout): Dropout(p=0.4258, inplace=False)\n",
      "  (linear): Linear(in_features=141, out_features=1, bias=True)\n",
      "  (act): Sigmoid()\n",
      ")\n",
      "3263\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Wrapper method to run training for hyperparameter optimization as in this case the function \r\n",
    "# to be optimized needs to return one float value\r\n",
    "def hyperparam_tune_run(train_dl, val_dl, params):\r\n",
    "    min_val_loss, _ = run_training(train_dl, val_dl, params)\r\n",
    "    return min_val_loss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "import optuna\r\n",
    "import time\r\n",
    "\r\n",
    "#[I 2021-10-21 12:06:44,242] Trial 15 finished with value: 0.4088201341421708 and parameters: \r\n",
    "# {'hidden_dim': 141, 'drop_out': 0.4257934114073623, 'learning_rate': 0.0003660548388149779, \r\n",
    "# 'num_layers': 2}. Best is trial 15 with value: 0.4088201341421708.\r\n",
    "\r\n",
    "def objective(trial):\r\n",
    "    params = {\r\n",
    "        \"hidden_dim\": trial.suggest_int(\"hidden_dim\", 32, 512),\r\n",
    "        \"drop_out\": trial.suggest_uniform(\"drop_out\", 0.2, 0.7),\r\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-3),\r\n",
    "        #\"is_bidirectional\": trial.suggest_int(\"is_bidirectional\", 0, 1),\r\n",
    "        \"num_layers\": trial.suggest_int(\"num_layers\", 1, 2)\r\n",
    "    }\r\n",
    "    loss = hyperparam_tune_run(train_dl, val_dl, params)\r\n",
    "    trial_num = trial.number\r\n",
    "    print(f\"loss at end of trial {trial_num} execution = {loss}\")\r\n",
    "    print(f\"trial {trial_num} params = {trial.params}\")\r\n",
    "    return loss\r\n",
    "\r\n",
    "study = optuna.create_study(direction=\"minimize\", study_name=\"DisasterModelTuning\")    \r\n",
    "study.optimize(objective, n_trials=20)\r\n",
    "print(\"Best trial:\")\r\n",
    "print(study.best_params)\r\n",
    "\r\n",
    "#Best trial:\r\n",
    "#{'hidden_dim': 141, 'drop_out': 0.4257934114073623, 'learning_rate': 0.0003660548388149779, 'num_layers': 2}"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-21 11:25:31,963]\u001b[0m A new study created in memory with name: DisasterModelTuning\u001b[0m\n",
      "D:\\InstalledSoftware\\anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.28595202687455995 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================================\n",
      "Epoch 0 :\n",
      "Execution time on training set = 25.65 seconds \n",
      "Training loss = 0.6851, training accuracy = 0.5663\n",
      "Execution time on validation set = 0.99 seconds \n",
      "Validation loss = 0.6766, validation accuracy = 0.5842\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 1 :\n",
      "Execution time on training set = 27.08 seconds \n",
      "Training loss = 0.6715, training accuracy = 0.5859\n",
      "Execution time on validation set = 0.86 seconds \n",
      "Validation loss = 0.6635, validation accuracy = 0.5883\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 2 :\n",
      "Execution time on training set = 23.92 seconds \n",
      "Training loss = 0.6548, training accuracy = 0.6161\n",
      "Execution time on validation set = 0.87 seconds \n",
      "Validation loss = 0.6413, validation accuracy = 0.6318\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 3 :\n",
      "Execution time on training set = 24.8 seconds \n",
      "Training loss = 0.6172, training accuracy = 0.6862\n",
      "Execution time on validation set = 0.86 seconds \n",
      "Validation loss = 0.5894, validation accuracy = 0.7588\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 4 :\n",
      "Execution time on training set = 25.01 seconds \n",
      "Training loss = 0.5602, training accuracy = 0.7518\n",
      "Execution time on validation set = 0.89 seconds \n",
      "Validation loss = 0.5308, validation accuracy = 0.7765\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 5 :\n",
      "Execution time on training set = 22.67 seconds \n",
      "Training loss = 0.5186, training accuracy = 0.7668\n",
      "Execution time on validation set = 0.88 seconds \n",
      "Validation loss = 0.4971, validation accuracy = 0.7982\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 6 :\n",
      "Execution time on training set = 24.08 seconds \n",
      "Training loss = 0.5, training accuracy = 0.776\n",
      "Execution time on validation set = 0.87 seconds \n",
      "Validation loss = 0.4895, validation accuracy = 0.7942\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 7 :\n",
      "Execution time on training set = 25.04 seconds \n",
      "Training loss = 0.4877, training accuracy = 0.7873\n",
      "Execution time on validation set = 0.9 seconds \n",
      "Validation loss = 0.4772, validation accuracy = 0.803\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 8 :\n",
      "Execution time on training set = 25.45 seconds \n",
      "Training loss = 0.478, training accuracy = 0.7929\n",
      "Execution time on validation set = 0.82 seconds \n",
      "Validation loss = 0.4748, validation accuracy = 0.7989\n",
      "=======================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-21 11:29:49,965]\u001b[0m Trial 0 finished with value: 0.46606087814206665 and parameters: {'hidden_dim': 450, 'drop_out': 0.28595202687455995, 'learning_rate': 1.180072487915846e-05, 'num_layers': 1}. Best is trial 0 with value: 0.46606087814206665.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================================\n",
      "Epoch 9 :\n",
      "Execution time on training set = 25.44 seconds \n",
      "Training loss = 0.4704, training accuracy = 0.7961\n",
      "Execution time on validation set = 0.88 seconds \n",
      "Validation loss = 0.4661, validation accuracy = 0.8037\n",
      "=======================================================\n",
      "loss at end of trial 0 execution = 0.46606087814206665\n",
      "trial 0 params = {'hidden_dim': 450, 'drop_out': 0.28595202687455995, 'learning_rate': 1.180072487915846e-05, 'num_layers': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "D:\\InstalledSoftware\\anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.22901101470238705 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================================\n",
      "Epoch 0 :\n",
      "Execution time on training set = 7.24 seconds \n",
      "Training loss = 0.5821, training accuracy = 0.6952\n",
      "Execution time on validation set = 0.39 seconds \n",
      "Validation loss = 0.4663, validation accuracy = 0.7996\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 1 :\n",
      "Execution time on training set = 8.08 seconds \n",
      "Training loss = 0.4543, training accuracy = 0.8023\n",
      "Execution time on validation set = 0.36 seconds \n",
      "Validation loss = 0.4382, validation accuracy = 0.8071\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 2 :\n",
      "Execution time on training set = 8.13 seconds \n",
      "Training loss = 0.4267, training accuracy = 0.8133\n",
      "Execution time on validation set = 0.38 seconds \n",
      "Validation loss = 0.431, validation accuracy = 0.8118\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 3 :\n",
      "Execution time on training set = 7.96 seconds \n",
      "Training loss = 0.4144, training accuracy = 0.8189\n",
      "Execution time on validation set = 0.37 seconds \n",
      "Validation loss = 0.4319, validation accuracy = 0.8084\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 4 :\n",
      "Execution time on training set = 8.13 seconds \n",
      "Training loss = 0.4033, training accuracy = 0.8232\n",
      "Execution time on validation set = 0.38 seconds \n",
      "Validation loss = 0.4316, validation accuracy = 0.8159\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 5 :\n",
      "Execution time on training set = 8.44 seconds \n",
      "Training loss = 0.3945, training accuracy = 0.8276\n",
      "Execution time on validation set = 0.68 seconds \n",
      "Validation loss = 0.4294, validation accuracy = 0.8084\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 6 :\n",
      "Execution time on training set = 8.58 seconds \n",
      "Training loss = 0.386, training accuracy = 0.8306\n",
      "Execution time on validation set = 0.36 seconds \n",
      "Validation loss = 0.434, validation accuracy = 0.8098\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 7 :\n",
      "Execution time on training set = 8.14 seconds \n",
      "Training loss = 0.3796, training accuracy = 0.8367\n",
      "Execution time on validation set = 0.35 seconds \n",
      "Validation loss = 0.4281, validation accuracy = 0.82\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 8 :\n",
      "Execution time on training set = 8.11 seconds \n",
      "Training loss = 0.367, training accuracy = 0.8406\n",
      "Execution time on validation set = 0.41 seconds \n",
      "Validation loss = 0.439, validation accuracy = 0.8193\n",
      "=======================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-21 11:31:14,843]\u001b[0m Trial 1 finished with value: 0.4264820166256117 and parameters: {'hidden_dim': 176, 'drop_out': 0.22901101470238705, 'learning_rate': 0.0002858590842902684, 'num_layers': 1}. Best is trial 1 with value: 0.4264820166256117.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================================\n",
      "Epoch 9 :\n",
      "Execution time on training set = 7.97 seconds \n",
      "Training loss = 0.3599, training accuracy = 0.8424\n",
      "Execution time on validation set = 0.37 seconds \n",
      "Validation loss = 0.4265, validation accuracy = 0.8173\n",
      "=======================================================\n",
      "loss at end of trial 1 execution = 0.4264820166256117\n",
      "trial 1 params = {'hidden_dim': 176, 'drop_out': 0.22901101470238705, 'learning_rate': 0.0002858590842902684, 'num_layers': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "D:\\InstalledSoftware\\anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6714768410303671 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================================\n",
      "Epoch 0 :\n",
      "Execution time on training set = 16.58 seconds \n",
      "Training loss = 0.5197, training accuracy = 0.7498\n",
      "Execution time on validation set = 0.62 seconds \n",
      "Validation loss = 0.4454, validation accuracy = 0.8037\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 1 :\n",
      "Execution time on training set = 16.07 seconds \n",
      "Training loss = 0.44, training accuracy = 0.8105\n",
      "Execution time on validation set = 0.63 seconds \n",
      "Validation loss = 0.4457, validation accuracy = 0.8064\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 2 :\n",
      "Execution time on training set = 16.17 seconds \n",
      "Training loss = 0.4176, training accuracy = 0.8188\n",
      "Execution time on validation set = 0.63 seconds \n",
      "Validation loss = 0.4307, validation accuracy = 0.8098\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 3 :\n",
      "Execution time on training set = 16.08 seconds \n",
      "Training loss = 0.4034, training accuracy = 0.8212\n",
      "Execution time on validation set = 0.65 seconds \n",
      "Validation loss = 0.4316, validation accuracy = 0.8105\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 4 :\n",
      "Execution time on training set = 14.17 seconds \n",
      "Training loss = 0.3897, training accuracy = 0.8308\n",
      "Execution time on validation set = 0.64 seconds \n",
      "Validation loss = 0.4365, validation accuracy = 0.8118\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 5 :\n",
      "Execution time on training set = 14.42 seconds \n",
      "Training loss = 0.3827, training accuracy = 0.8324\n",
      "Execution time on validation set = 0.67 seconds \n",
      "Validation loss = 0.4489, validation accuracy = 0.8179\n",
      "=======================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-21 11:33:07,416]\u001b[0m Trial 2 finished with value: 0.4306647647982058 and parameters: {'hidden_dim': 311, 'drop_out': 0.6714768410303671, 'learning_rate': 0.0006091971942534142, 'num_layers': 1}. Best is trial 1 with value: 0.4264820166256117.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================================\n",
      "Epoch 6 :\n",
      "Execution time on training set = 14.62 seconds \n",
      "Training loss = 0.3579, training accuracy = 0.8467\n",
      "Execution time on validation set = 0.56 seconds \n",
      "Validation loss = 0.4367, validation accuracy = 0.8166\n",
      "=======================================================\n",
      "loss at end of trial 2 execution = 0.4306647647982058\n",
      "trial 2 params = {'hidden_dim': 311, 'drop_out': 0.6714768410303671, 'learning_rate': 0.0006091971942534142, 'num_layers': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "D:\\InstalledSoftware\\anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.36748850411197787 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================================\n",
      "Epoch 0 :\n",
      "Execution time on training set = 10.77 seconds \n",
      "Training loss = 0.6265, training accuracy = 0.6554\n",
      "Execution time on validation set = 0.49 seconds \n",
      "Validation loss = 0.5326, validation accuracy = 0.7466\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 1 :\n",
      "Execution time on training set = 11.22 seconds \n",
      "Training loss = 0.4852, training accuracy = 0.7867\n",
      "Execution time on validation set = 0.45 seconds \n",
      "Validation loss = 0.4501, validation accuracy = 0.8098\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 2 :\n",
      "Execution time on training set = 11.51 seconds \n",
      "Training loss = 0.4442, training accuracy = 0.8087\n",
      "Execution time on validation set = 0.49 seconds \n",
      "Validation loss = 0.4411, validation accuracy = 0.8071\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 3 :\n",
      "Execution time on training set = 10.13 seconds \n",
      "Training loss = 0.4303, training accuracy = 0.8107\n",
      "Execution time on validation set = 0.49 seconds \n",
      "Validation loss = 0.426, validation accuracy = 0.8159\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 4 :\n",
      "Execution time on training set = 10.07 seconds \n",
      "Training loss = 0.4178, training accuracy = 0.8163\n",
      "Execution time on validation set = 0.46 seconds \n",
      "Validation loss = 0.4273, validation accuracy = 0.8098\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 5 :\n",
      "Execution time on training set = 10.09 seconds \n",
      "Training loss = 0.4117, training accuracy = 0.8214\n",
      "Execution time on validation set = 0.48 seconds \n",
      "Validation loss = 0.425, validation accuracy = 0.8132\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 6 :\n",
      "Execution time on training set = 10.24 seconds \n",
      "Training loss = 0.4024, training accuracy = 0.828\n",
      "Execution time on validation set = 0.54 seconds \n",
      "Validation loss = 0.4255, validation accuracy = 0.8145\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 7 :\n",
      "Execution time on training set = 10.12 seconds \n",
      "Training loss = 0.3998, training accuracy = 0.8268\n",
      "Execution time on validation set = 0.44 seconds \n",
      "Validation loss = 0.4241, validation accuracy = 0.8173\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 8 :\n",
      "Execution time on training set = 10.08 seconds \n",
      "Training loss = 0.3936, training accuracy = 0.8324\n",
      "Execution time on validation set = 0.49 seconds \n",
      "Validation loss = 0.422, validation accuracy = 0.8173\n",
      "=======================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-21 11:34:56,604]\u001b[0m Trial 3 finished with value: 0.4220047346923662 and parameters: {'hidden_dim': 244, 'drop_out': 0.36748850411197787, 'learning_rate': 0.00013161988541106158, 'num_layers': 1}. Best is trial 3 with value: 0.4220047346923662.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================================\n",
      "Epoch 9 :\n",
      "Execution time on training set = 10.13 seconds \n",
      "Training loss = 0.3847, training accuracy = 0.8368\n",
      "Execution time on validation set = 0.46 seconds \n",
      "Validation loss = 0.429, validation accuracy = 0.8152\n",
      "=======================================================\n",
      "loss at end of trial 3 execution = 0.4220047346923662\n",
      "trial 3 params = {'hidden_dim': 244, 'drop_out': 0.36748850411197787, 'learning_rate': 0.00013161988541106158, 'num_layers': 1}\n",
      "=======================================================\n",
      "Epoch 0 :\n",
      "Execution time on training set = 31.78 seconds \n",
      "Training loss = 0.6826, training accuracy = 0.5681\n",
      "Execution time on validation set = 1.26 seconds \n",
      "Validation loss = 0.6696, validation accuracy = 0.5747\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 1 :\n",
      "Execution time on training set = 31.91 seconds \n",
      "Training loss = 0.6459, training accuracy = 0.612\n",
      "Execution time on validation set = 1.27 seconds \n",
      "Validation loss = 0.5952, validation accuracy = 0.7269\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 2 :\n",
      "Execution time on training set = 32.18 seconds \n",
      "Training loss = 0.5528, training accuracy = 0.7539\n",
      "Execution time on validation set = 1.25 seconds \n",
      "Validation loss = 0.4947, validation accuracy = 0.7853\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 3 :\n",
      "Execution time on training set = 31.73 seconds \n",
      "Training loss = 0.4947, training accuracy = 0.7791\n",
      "Execution time on validation set = 1.4 seconds \n",
      "Validation loss = 0.4685, validation accuracy = 0.803\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 4 :\n",
      "Execution time on training set = 32.36 seconds \n",
      "Training loss = 0.4732, training accuracy = 0.791\n",
      "Execution time on validation set = 1.3 seconds \n",
      "Validation loss = 0.4712, validation accuracy = 0.8071\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 5 :\n",
      "Execution time on training set = 34.17 seconds \n",
      "Training loss = 0.4631, training accuracy = 0.7947\n",
      "Execution time on validation set = 1.33 seconds \n",
      "Validation loss = 0.4557, validation accuracy = 0.8159\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 6 :\n",
      "Execution time on training set = 34.28 seconds \n",
      "Training loss = 0.4542, training accuracy = 0.802\n",
      "Execution time on validation set = 1.23 seconds \n",
      "Validation loss = 0.4481, validation accuracy = 0.8207\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 7 :\n",
      "Execution time on training set = 32.55 seconds \n",
      "Training loss = 0.4492, training accuracy = 0.8038\n",
      "Execution time on validation set = 1.25 seconds \n",
      "Validation loss = 0.4457, validation accuracy = 0.8173\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 8 :\n",
      "Execution time on training set = 32.66 seconds \n",
      "Training loss = 0.4445, training accuracy = 0.8071\n",
      "Execution time on validation set = 1.32 seconds \n",
      "Validation loss = 0.4443, validation accuracy = 0.8166\n",
      "=======================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-21 11:40:34,807]\u001b[0m Trial 4 finished with value: 0.44251136416974274 and parameters: {'hidden_dim': 331, 'drop_out': 0.3538961202773002, 'learning_rate': 2.2328023942010257e-05, 'num_layers': 2}. Best is trial 3 with value: 0.4220047346923662.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================================\n",
      "Epoch 9 :\n",
      "Execution time on training set = 31.62 seconds \n",
      "Training loss = 0.44, training accuracy = 0.8086\n",
      "Execution time on validation set = 1.28 seconds \n",
      "Validation loss = 0.4425, validation accuracy = 0.8118\n",
      "=======================================================\n",
      "loss at end of trial 4 execution = 0.44251136416974274\n",
      "trial 4 params = {'hidden_dim': 331, 'drop_out': 0.3538961202773002, 'learning_rate': 2.2328023942010257e-05, 'num_layers': 2}\n",
      "=======================================================\n",
      "Epoch 0 :\n",
      "Execution time on training set = 35.83 seconds \n",
      "Training loss = 0.6854, training accuracy = 0.5653\n",
      "Execution time on validation set = 1.43 seconds \n",
      "Validation loss = 0.6748, validation accuracy = 0.5781\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 1 :\n",
      "Execution time on training set = 36.37 seconds \n",
      "Training loss = 0.6607, training accuracy = 0.5829\n",
      "Execution time on validation set = 1.33 seconds \n",
      "Validation loss = 0.6303, validation accuracy = 0.6461\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 2 :\n",
      "Execution time on training set = 34.93 seconds \n",
      "Training loss = 0.59, training accuracy = 0.7222\n",
      "Execution time on validation set = 1.4 seconds \n",
      "Validation loss = 0.5456, validation accuracy = 0.7568\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 3 :\n",
      "Execution time on training set = 35.73 seconds \n",
      "Training loss = 0.517, training accuracy = 0.7669\n",
      "Execution time on validation set = 1.32 seconds \n",
      "Validation loss = 0.493, validation accuracy = 0.786\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 4 :\n",
      "Execution time on training set = 35.38 seconds \n",
      "Training loss = 0.4866, training accuracy = 0.7798\n",
      "Execution time on validation set = 1.45 seconds \n",
      "Validation loss = 0.4726, validation accuracy = 0.8016\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 5 :\n",
      "Execution time on training set = 35.02 seconds \n",
      "Training loss = 0.4708, training accuracy = 0.7926\n",
      "Execution time on validation set = 1.35 seconds \n",
      "Validation loss = 0.4694, validation accuracy = 0.8023\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 6 :\n",
      "Execution time on training set = 34.92 seconds \n",
      "Training loss = 0.4605, training accuracy = 0.7944\n",
      "Execution time on validation set = 1.31 seconds \n",
      "Validation loss = 0.4618, validation accuracy = 0.8132\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 7 :\n",
      "Execution time on training set = 35.26 seconds \n",
      "Training loss = 0.4538, training accuracy = 0.7979\n",
      "Execution time on validation set = 1.34 seconds \n",
      "Validation loss = 0.4614, validation accuracy = 0.8084\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 8 :\n",
      "Execution time on training set = 35.49 seconds \n",
      "Training loss = 0.4492, training accuracy = 0.8007\n",
      "Execution time on validation set = 1.32 seconds \n",
      "Validation loss = 0.456, validation accuracy = 0.8084\n",
      "=======================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-21 11:46:42,078]\u001b[0m Trial 5 finished with value: 0.446911818307379 and parameters: {'hidden_dim': 364, 'drop_out': 0.5235184823245838, 'learning_rate': 1.8453993261268184e-05, 'num_layers': 2}. Best is trial 3 with value: 0.4220047346923662.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================================\n",
      "Epoch 9 :\n",
      "Execution time on training set = 34.71 seconds \n",
      "Training loss = 0.4445, training accuracy = 0.8041\n",
      "Execution time on validation set = 1.32 seconds \n",
      "Validation loss = 0.4469, validation accuracy = 0.8105\n",
      "=======================================================\n",
      "loss at end of trial 5 execution = 0.446911818307379\n",
      "trial 5 params = {'hidden_dim': 364, 'drop_out': 0.5235184823245838, 'learning_rate': 1.8453993261268184e-05, 'num_layers': 2}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "D:\\InstalledSoftware\\anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5498969472117253 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================================\n",
      "Epoch 0 :\n",
      "Execution time on training set = 22.96 seconds \n",
      "Training loss = 0.6789, training accuracy = 0.5827\n",
      "Execution time on validation set = 0.93 seconds \n",
      "Validation loss = 0.6646, validation accuracy = 0.5985\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 1 :\n",
      "Execution time on training set = 23.25 seconds \n",
      "Training loss = 0.6363, training accuracy = 0.6498\n",
      "Execution time on validation set = 0.89 seconds \n",
      "Validation loss = 0.5877, validation accuracy = 0.7643\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 2 :\n",
      "Execution time on training set = 22.62 seconds \n",
      "Training loss = 0.5378, training accuracy = 0.7638\n",
      "Execution time on validation set = 0.84 seconds \n",
      "Validation loss = 0.5036, validation accuracy = 0.7948\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 3 :\n",
      "Execution time on training set = 22.64 seconds \n",
      "Training loss = 0.4939, training accuracy = 0.7803\n",
      "Execution time on validation set = 0.84 seconds \n",
      "Validation loss = 0.4734, validation accuracy = 0.803\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 4 :\n",
      "Execution time on training set = 25.28 seconds \n",
      "Training loss = 0.4712, training accuracy = 0.7921\n",
      "Execution time on validation set = 1.08 seconds \n",
      "Validation loss = 0.4625, validation accuracy = 0.805\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 5 :\n",
      "Execution time on training set = 23.15 seconds \n",
      "Training loss = 0.4579, training accuracy = 0.7982\n",
      "Execution time on validation set = 0.84 seconds \n",
      "Validation loss = 0.4541, validation accuracy = 0.8064\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 6 :\n",
      "Execution time on training set = 22.79 seconds \n",
      "Training loss = 0.4472, training accuracy = 0.8016\n",
      "Execution time on validation set = 0.83 seconds \n",
      "Validation loss = 0.4495, validation accuracy = 0.8043\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 7 :\n",
      "Execution time on training set = 22.65 seconds \n",
      "Training loss = 0.4396, training accuracy = 0.8056\n",
      "Execution time on validation set = 0.85 seconds \n",
      "Validation loss = 0.4466, validation accuracy = 0.8023\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 8 :\n",
      "Execution time on training set = 23.06 seconds \n",
      "Training loss = 0.4356, training accuracy = 0.8079\n",
      "Execution time on validation set = 0.86 seconds \n",
      "Validation loss = 0.4444, validation accuracy = 0.803\n",
      "=======================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-21 11:50:42,128]\u001b[0m Trial 6 finished with value: 0.4382596974787505 and parameters: {'hidden_dim': 479, 'drop_out': 0.5498969472117253, 'learning_rate': 2.7073022393504273e-05, 'num_layers': 1}. Best is trial 3 with value: 0.4220047346923662.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================================\n",
      "Epoch 9 :\n",
      "Execution time on training set = 22.75 seconds \n",
      "Training loss = 0.4299, training accuracy = 0.8067\n",
      "Execution time on validation set = 0.89 seconds \n",
      "Validation loss = 0.4383, validation accuracy = 0.803\n",
      "=======================================================\n",
      "loss at end of trial 6 execution = 0.4382596974787505\n",
      "trial 6 params = {'hidden_dim': 479, 'drop_out': 0.5498969472117253, 'learning_rate': 2.7073022393504273e-05, 'num_layers': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "D:\\InstalledSoftware\\anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.21011060364170903 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================================\n",
      "Epoch 0 :\n",
      "Execution time on training set = 7.93 seconds \n",
      "Training loss = 0.688, training accuracy = 0.5438\n",
      "Execution time on validation set = 0.38 seconds \n",
      "Validation loss = 0.6787, validation accuracy = 0.5876\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 1 :\n",
      "Execution time on training set = 7.95 seconds \n",
      "Training loss = 0.6706, training accuracy = 0.5924\n",
      "Execution time on validation set = 0.39 seconds \n",
      "Validation loss = 0.6606, validation accuracy = 0.6094\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 2 :\n",
      "Execution time on training set = 8.02 seconds \n",
      "Training loss = 0.6489, training accuracy = 0.6253\n",
      "Execution time on validation set = 0.38 seconds \n",
      "Validation loss = 0.6313, validation accuracy = 0.6671\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 3 :\n",
      "Execution time on training set = 7.93 seconds \n",
      "Training loss = 0.601, training accuracy = 0.7123\n",
      "Execution time on validation set = 0.37 seconds \n",
      "Validation loss = 0.5665, validation accuracy = 0.7643\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 4 :\n",
      "Execution time on training set = 7.95 seconds \n",
      "Training loss = 0.5369, training accuracy = 0.7641\n",
      "Execution time on validation set = 0.38 seconds \n",
      "Validation loss = 0.515, validation accuracy = 0.7663\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 5 :\n",
      "Execution time on training set = 7.97 seconds \n",
      "Training loss = 0.5007, training accuracy = 0.778\n",
      "Execution time on validation set = 0.43 seconds \n",
      "Validation loss = 0.4855, validation accuracy = 0.7914\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 6 :\n",
      "Execution time on training set = 7.94 seconds \n",
      "Training loss = 0.4812, training accuracy = 0.7923\n",
      "Execution time on validation set = 0.37 seconds \n",
      "Validation loss = 0.4765, validation accuracy = 0.7969\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 7 :\n",
      "Execution time on training set = 8.16 seconds \n",
      "Training loss = 0.469, training accuracy = 0.7969\n",
      "Execution time on validation set = 0.41 seconds \n",
      "Validation loss = 0.468, validation accuracy = 0.805\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 8 :\n",
      "Execution time on training set = 7.99 seconds \n",
      "Training loss = 0.4579, training accuracy = 0.8008\n",
      "Execution time on validation set = 0.35 seconds \n",
      "Validation loss = 0.4611, validation accuracy = 0.8118\n",
      "=======================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-21 11:52:05,830]\u001b[0m Trial 7 finished with value: 0.4578768533209096 and parameters: {'hidden_dim': 206, 'drop_out': 0.21011060364170903, 'learning_rate': 2.517684862663182e-05, 'num_layers': 1}. Best is trial 3 with value: 0.4220047346923662.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================================\n",
      "Epoch 9 :\n",
      "Execution time on training set = 8.01 seconds \n",
      "Training loss = 0.4494, training accuracy = 0.8067\n",
      "Execution time on validation set = 0.36 seconds \n",
      "Validation loss = 0.4579, validation accuracy = 0.8084\n",
      "=======================================================\n",
      "loss at end of trial 7 execution = 0.4578768533209096\n",
      "trial 7 params = {'hidden_dim': 206, 'drop_out': 0.21011060364170903, 'learning_rate': 2.517684862663182e-05, 'num_layers': 1}\n",
      "=======================================================\n",
      "Epoch 0 :\n",
      "Execution time on training set = 19.7 seconds \n",
      "Training loss = 0.5584, training accuracy = 0.7125\n",
      "Execution time on validation set = 0.86 seconds \n",
      "Validation loss = 0.4524, validation accuracy = 0.8091\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 1 :\n",
      "Execution time on training set = 19.49 seconds \n",
      "Training loss = 0.4455, training accuracy = 0.8038\n",
      "Execution time on validation set = 0.87 seconds \n",
      "Validation loss = 0.4407, validation accuracy = 0.8139\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 2 :\n",
      "Execution time on training set = 19.52 seconds \n",
      "Training loss = 0.4234, training accuracy = 0.8163\n",
      "Execution time on validation set = 0.88 seconds \n",
      "Validation loss = 0.4294, validation accuracy = 0.82\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 3 :\n",
      "Execution time on training set = 19.38 seconds \n",
      "Training loss = 0.411, training accuracy = 0.8209\n",
      "Execution time on validation set = 0.95 seconds \n",
      "Validation loss = 0.4309, validation accuracy = 0.8193\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 4 :\n",
      "Execution time on training set = 19.41 seconds \n",
      "Training loss = 0.3991, training accuracy = 0.8286\n",
      "Execution time on validation set = 0.84 seconds \n",
      "Validation loss = 0.422, validation accuracy = 0.824\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 5 :\n",
      "Execution time on training set = 19.37 seconds \n",
      "Training loss = 0.3837, training accuracy = 0.8324\n",
      "Execution time on validation set = 0.9 seconds \n",
      "Validation loss = 0.4244, validation accuracy = 0.8213\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 6 :\n",
      "Execution time on training set = 19.48 seconds \n",
      "Training loss = 0.3747, training accuracy = 0.8411\n",
      "Execution time on validation set = 0.84 seconds \n",
      "Validation loss = 0.4185, validation accuracy = 0.8261\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 7 :\n",
      "Execution time on training set = 19.58 seconds \n",
      "Training loss = 0.3597, training accuracy = 0.8479\n",
      "Execution time on validation set = 0.89 seconds \n",
      "Validation loss = 0.4369, validation accuracy = 0.8145\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 8 :\n",
      "Execution time on training set = 19.3 seconds \n",
      "Training loss = 0.3548, training accuracy = 0.849\n",
      "Execution time on validation set = 0.85 seconds \n",
      "Validation loss = 0.4424, validation accuracy = 0.8159\n",
      "=======================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-21 11:55:29,227]\u001b[0m Trial 8 finished with value: 0.4185144434804502 and parameters: {'hidden_dim': 246, 'drop_out': 0.2367919730827701, 'learning_rate': 0.0002742976105796984, 'num_layers': 2}. Best is trial 8 with value: 0.4185144434804502.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================================\n",
      "Epoch 9 :\n",
      "Execution time on training set = 19.4 seconds \n",
      "Training loss = 0.3386, training accuracy = 0.8597\n",
      "Execution time on validation set = 0.84 seconds \n",
      "Validation loss = 0.46, validation accuracy = 0.8173\n",
      "=======================================================\n",
      "loss at end of trial 8 execution = 0.4185144434804502\n",
      "trial 8 params = {'hidden_dim': 246, 'drop_out': 0.2367919730827701, 'learning_rate': 0.0002742976105796984, 'num_layers': 2}\n",
      "=======================================================\n",
      "Epoch 0 :\n",
      "Execution time on training set = 4.76 seconds \n",
      "Training loss = 0.7005, training accuracy = 0.4301\n",
      "Execution time on validation set = 0.25 seconds \n",
      "Validation loss = 0.7009, validation accuracy = 0.4239\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 1 :\n",
      "Execution time on training set = 3.25 seconds \n",
      "Training loss = 0.7006, training accuracy = 0.4312\n",
      "Execution time on validation set = 0.3 seconds \n",
      "Validation loss = 0.7004, validation accuracy = 0.4246\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 2 :\n",
      "Execution time on training set = 3.29 seconds \n",
      "Training loss = 0.6996, training accuracy = 0.4308\n",
      "Execution time on validation set = 0.23 seconds \n",
      "Validation loss = 0.6997, validation accuracy = 0.4253\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 3 :\n",
      "Execution time on training set = 3.15 seconds \n",
      "Training loss = 0.6991, training accuracy = 0.4326\n",
      "Execution time on validation set = 0.28 seconds \n",
      "Validation loss = 0.6993, validation accuracy = 0.4239\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 4 :\n",
      "Execution time on training set = 3.23 seconds \n",
      "Training loss = 0.6989, training accuracy = 0.4324\n",
      "Execution time on validation set = 0.26 seconds \n",
      "Validation loss = 0.6984, validation accuracy = 0.4287\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 5 :\n",
      "Execution time on training set = 3.16 seconds \n",
      "Training loss = 0.6982, training accuracy = 0.4336\n",
      "Execution time on validation set = 0.29 seconds \n",
      "Validation loss = 0.6979, validation accuracy = 0.4273\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 6 :\n",
      "Execution time on training set = 3.2 seconds \n",
      "Training loss = 0.6978, training accuracy = 0.4326\n",
      "Execution time on validation set = 0.31 seconds \n",
      "Validation loss = 0.6974, validation accuracy = 0.4266\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 7 :\n",
      "Execution time on training set = 3.14 seconds \n",
      "Training loss = 0.6973, training accuracy = 0.4367\n",
      "Execution time on validation set = 0.28 seconds \n",
      "Validation loss = 0.6971, validation accuracy = 0.4239\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 8 :\n",
      "Execution time on training set = 3.22 seconds \n",
      "Training loss = 0.6968, training accuracy = 0.4393\n",
      "Execution time on validation set = 0.28 seconds \n",
      "Validation loss = 0.6964, validation accuracy = 0.4266\n",
      "=======================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-21 11:56:05,601]\u001b[0m Trial 9 finished with value: 0.6958785808604696 and parameters: {'hidden_dim': 53, 'drop_out': 0.23971792802943304, 'learning_rate': 1.9140771529830844e-06, 'num_layers': 2}. Best is trial 8 with value: 0.4185144434804502.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================================\n",
      "Epoch 9 :\n",
      "Execution time on training set = 3.15 seconds \n",
      "Training loss = 0.6963, training accuracy = 0.4459\n",
      "Execution time on validation set = 0.29 seconds \n",
      "Validation loss = 0.6959, validation accuracy = 0.428\n",
      "=======================================================\n",
      "loss at end of trial 9 execution = 0.6958785808604696\n",
      "trial 9 params = {'hidden_dim': 53, 'drop_out': 0.23971792802943304, 'learning_rate': 1.9140771529830844e-06, 'num_layers': 2}\n",
      "=======================================================\n",
      "Epoch 0 :\n",
      "Execution time on training set = 8.7 seconds \n",
      "Training loss = 0.6732, training accuracy = 0.5538\n",
      "Execution time on validation set = 0.44 seconds \n",
      "Validation loss = 0.6127, validation accuracy = 0.6943\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 1 :\n",
      "Execution time on training set = 8.59 seconds \n",
      "Training loss = 0.5396, training accuracy = 0.7492\n",
      "Execution time on validation set = 0.41 seconds \n",
      "Validation loss = 0.4699, validation accuracy = 0.7908\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 2 :\n",
      "Execution time on training set = 8.58 seconds \n",
      "Training loss = 0.4686, training accuracy = 0.7921\n",
      "Execution time on validation set = 0.44 seconds \n",
      "Validation loss = 0.4571, validation accuracy = 0.8003\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 3 :\n",
      "Execution time on training set = 8.66 seconds \n",
      "Training loss = 0.4512, training accuracy = 0.8033\n",
      "Execution time on validation set = 0.45 seconds \n",
      "Validation loss = 0.4545, validation accuracy = 0.8043\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 4 :\n",
      "Execution time on training set = 8.63 seconds \n",
      "Training loss = 0.4392, training accuracy = 0.8056\n",
      "Execution time on validation set = 0.39 seconds \n",
      "Validation loss = 0.4442, validation accuracy = 0.8084\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 5 :\n",
      "Execution time on training set = 8.67 seconds \n",
      "Training loss = 0.4358, training accuracy = 0.8056\n",
      "Execution time on validation set = 0.48 seconds \n",
      "Validation loss = 0.4443, validation accuracy = 0.8145\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 6 :\n",
      "Execution time on training set = 8.8 seconds \n",
      "Training loss = 0.4276, training accuracy = 0.8137\n",
      "Execution time on validation set = 0.51 seconds \n",
      "Validation loss = 0.4331, validation accuracy = 0.8186\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 7 :\n",
      "Execution time on training set = 8.73 seconds \n",
      "Training loss = 0.4201, training accuracy = 0.8169\n",
      "Execution time on validation set = 0.42 seconds \n",
      "Validation loss = 0.4416, validation accuracy = 0.8064\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 8 :\n",
      "Execution time on training set = 8.71 seconds \n",
      "Training loss = 0.4173, training accuracy = 0.8207\n",
      "Execution time on validation set = 0.52 seconds \n",
      "Validation loss = 0.4402, validation accuracy = 0.8159\n",
      "=======================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-21 11:57:38,805]\u001b[0m Trial 10 finished with value: 0.4286364938901818 and parameters: {'hidden_dim': 107, 'drop_out': 0.41424807438263095, 'learning_rate': 0.00011780879580204523, 'num_layers': 2}. Best is trial 8 with value: 0.4185144434804502.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================================\n",
      "Epoch 9 :\n",
      "Execution time on training set = 8.88 seconds \n",
      "Training loss = 0.4134, training accuracy = 0.8212\n",
      "Execution time on validation set = 0.41 seconds \n",
      "Validation loss = 0.4286, validation accuracy = 0.8152\n",
      "=======================================================\n",
      "loss at end of trial 10 execution = 0.4286364938901818\n",
      "trial 10 params = {'hidden_dim': 107, 'drop_out': 0.41424807438263095, 'learning_rate': 0.00011780879580204523, 'num_layers': 2}\n",
      "=======================================================\n",
      "Epoch 0 :\n",
      "Execution time on training set = 17.69 seconds \n",
      "Training loss = 0.5997, training accuracy = 0.6676\n",
      "Execution time on validation set = 0.82 seconds \n",
      "Validation loss = 0.5129, validation accuracy = 0.7663\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 1 :\n",
      "Execution time on training set = 18.4 seconds \n",
      "Training loss = 0.469, training accuracy = 0.7914\n",
      "Execution time on validation set = 0.86 seconds \n",
      "Validation loss = 0.4469, validation accuracy = 0.8037\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 2 :\n",
      "Execution time on training set = 17.47 seconds \n",
      "Training loss = 0.4406, training accuracy = 0.811\n",
      "Execution time on validation set = 0.76 seconds \n",
      "Validation loss = 0.4396, validation accuracy = 0.8071\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 3 :\n",
      "Execution time on training set = 17.36 seconds \n",
      "Training loss = 0.4296, training accuracy = 0.8099\n",
      "Execution time on validation set = 0.81 seconds \n",
      "Validation loss = 0.4397, validation accuracy = 0.8132\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 4 :\n",
      "Execution time on training set = 17.22 seconds \n",
      "Training loss = 0.4174, training accuracy = 0.8192\n",
      "Execution time on validation set = 0.79 seconds \n",
      "Validation loss = 0.4311, validation accuracy = 0.8179\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 5 :\n",
      "Execution time on training set = 17.3 seconds \n",
      "Training loss = 0.4099, training accuracy = 0.8209\n",
      "Execution time on validation set = 0.74 seconds \n",
      "Validation loss = 0.4139, validation accuracy = 0.8193\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 6 :\n",
      "Execution time on training set = 17.24 seconds \n",
      "Training loss = 0.4061, training accuracy = 0.8225\n",
      "Execution time on validation set = 0.75 seconds \n",
      "Validation loss = 0.4256, validation accuracy = 0.8145\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 7 :\n",
      "Execution time on training set = 17.38 seconds \n",
      "Training loss = 0.3921, training accuracy = 0.8331\n",
      "Execution time on validation set = 0.74 seconds \n",
      "Validation loss = 0.4231, validation accuracy = 0.8173\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 8 :\n",
      "Execution time on training set = 20.07 seconds \n",
      "Training loss = 0.3903, training accuracy = 0.8336\n",
      "Execution time on validation set = 0.8 seconds \n",
      "Validation loss = 0.418, validation accuracy = 0.8227\n",
      "=======================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-21 12:00:46,035]\u001b[0m Trial 11 finished with value: 0.4139311838409175 and parameters: {'hidden_dim': 222, 'drop_out': 0.3331923202395338, 'learning_rate': 0.00014612074684655784, 'num_layers': 2}. Best is trial 11 with value: 0.4139311838409175.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================================\n",
      "Epoch 9 :\n",
      "Execution time on training set = 19.13 seconds \n",
      "Training loss = 0.3813, training accuracy = 0.8339\n",
      "Execution time on validation set = 0.83 seconds \n",
      "Validation loss = 0.4406, validation accuracy = 0.8139\n",
      "=======================================================\n",
      "loss at end of trial 11 execution = 0.4139311838409175\n",
      "trial 11 params = {'hidden_dim': 222, 'drop_out': 0.3331923202395338, 'learning_rate': 0.00014612074684655784, 'num_layers': 2}\n",
      "=======================================================\n",
      "Epoch 0 :\n",
      "Execution time on training set = 12.86 seconds \n",
      "Training loss = 0.5066, training accuracy = 0.7584\n",
      "Execution time on validation set = 0.54 seconds \n",
      "Validation loss = 0.4433, validation accuracy = 0.805\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 1 :\n",
      "Execution time on training set = 12.37 seconds \n",
      "Training loss = 0.4299, training accuracy = 0.8158\n",
      "Execution time on validation set = 0.54 seconds \n",
      "Validation loss = 0.4432, validation accuracy = 0.8077\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 2 :\n",
      "Execution time on training set = 11.92 seconds \n",
      "Training loss = 0.4136, training accuracy = 0.822\n",
      "Execution time on validation set = 0.58 seconds \n",
      "Validation loss = 0.4245, validation accuracy = 0.8193\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 3 :\n",
      "Execution time on training set = 11.93 seconds \n",
      "Training loss = 0.3875, training accuracy = 0.8347\n",
      "Execution time on validation set = 0.57 seconds \n",
      "Validation loss = 0.415, validation accuracy = 0.8234\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 4 :\n",
      "Execution time on training set = 11.96 seconds \n",
      "Training loss = 0.3667, training accuracy = 0.8469\n",
      "Execution time on validation set = 0.6 seconds \n",
      "Validation loss = 0.4334, validation accuracy = 0.8084\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 5 :\n",
      "Execution time on training set = 11.9 seconds \n",
      "Training loss = 0.3511, training accuracy = 0.8528\n",
      "Execution time on validation set = 0.54 seconds \n",
      "Validation loss = 0.443, validation accuracy = 0.8084\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 6 :\n",
      "Execution time on training set = 11.93 seconds \n",
      "Training loss = 0.3143, training accuracy = 0.8689\n",
      "Execution time on validation set = 0.58 seconds \n",
      "Validation loss = 0.4505, validation accuracy = 0.8159\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 7 :\n",
      "Execution time on training set = 11.82 seconds \n",
      "Training loss = 0.2787, training accuracy = 0.8883\n",
      "Execution time on validation set = 0.57 seconds \n",
      "Validation loss = 0.5049, validation accuracy = 0.8003\n",
      "=======================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-21 12:02:39,818]\u001b[0m Trial 12 finished with value: 0.4150034506683764 and parameters: {'hidden_dim': 145, 'drop_out': 0.31387071451863036, 'learning_rate': 0.0009301963478783436, 'num_layers': 2}. Best is trial 11 with value: 0.4139311838409175.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================================\n",
      "Epoch 8 :\n",
      "Execution time on training set = 11.91 seconds \n",
      "Training loss = 0.2449, training accuracy = 0.9016\n",
      "Execution time on validation set = 0.6 seconds \n",
      "Validation loss = 0.5227, validation accuracy = 0.7921\n",
      "=======================================================\n",
      "loss at end of trial 12 execution = 0.4150034506683764\n",
      "trial 12 params = {'hidden_dim': 145, 'drop_out': 0.31387071451863036, 'learning_rate': 0.0009301963478783436, 'num_layers': 2}\n",
      "=======================================================\n",
      "Epoch 0 :\n",
      "Execution time on training set = 11.58 seconds \n",
      "Training loss = 0.527, training accuracy = 0.7414\n",
      "Execution time on validation set = 0.53 seconds \n",
      "Validation loss = 0.4648, validation accuracy = 0.8043\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 1 :\n",
      "Execution time on training set = 11.66 seconds \n",
      "Training loss = 0.4381, training accuracy = 0.8097\n",
      "Execution time on validation set = 0.53 seconds \n",
      "Validation loss = 0.4211, validation accuracy = 0.8227\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 2 :\n",
      "Execution time on training set = 11.76 seconds \n",
      "Training loss = 0.4075, training accuracy = 0.8283\n",
      "Execution time on validation set = 0.54 seconds \n",
      "Validation loss = 0.4406, validation accuracy = 0.8043\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 3 :\n",
      "Execution time on training set = 11.6 seconds \n",
      "Training loss = 0.3879, training accuracy = 0.8304\n",
      "Execution time on validation set = 0.56 seconds \n",
      "Validation loss = 0.4222, validation accuracy = 0.8193\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 4 :\n",
      "Execution time on training set = 11.67 seconds \n",
      "Training loss = 0.3606, training accuracy = 0.8477\n",
      "Execution time on validation set = 0.51 seconds \n",
      "Validation loss = 0.424, validation accuracy = 0.8254\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 5 :\n",
      "Execution time on training set = 11.78 seconds \n",
      "Training loss = 0.3377, training accuracy = 0.8595\n",
      "Execution time on validation set = 0.52 seconds \n",
      "Validation loss = 0.4381, validation accuracy = 0.8084\n",
      "=======================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-21 12:04:05,410]\u001b[0m Trial 13 finished with value: 0.42112406829129095 and parameters: {'hidden_dim': 142, 'drop_out': 0.3310838714434736, 'learning_rate': 0.000972002153218266, 'num_layers': 2}. Best is trial 11 with value: 0.4139311838409175.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================================\n",
      "Epoch 6 :\n",
      "Execution time on training set = 11.69 seconds \n",
      "Training loss = 0.3081, training accuracy = 0.8727\n",
      "Execution time on validation set = 0.59 seconds \n",
      "Validation loss = 0.4704, validation accuracy = 0.8043\n",
      "=======================================================\n",
      "loss at end of trial 13 execution = 0.42112406829129095\n",
      "trial 13 params = {'hidden_dim': 142, 'drop_out': 0.3310838714434736, 'learning_rate': 0.000972002153218266, 'num_layers': 2}\n",
      "=======================================================\n",
      "Epoch 0 :\n",
      "Execution time on training set = 3.52 seconds \n",
      "Training loss = 0.6876, training accuracy = 0.5607\n",
      "Execution time on validation set = 0.32 seconds \n",
      "Validation loss = 0.6812, validation accuracy = 0.5734\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 1 :\n",
      "Execution time on training set = 3.55 seconds \n",
      "Training loss = 0.6731, training accuracy = 0.5796\n",
      "Execution time on validation set = 0.33 seconds \n",
      "Validation loss = 0.6574, validation accuracy = 0.5917\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 2 :\n",
      "Execution time on training set = 3.56 seconds \n",
      "Training loss = 0.6159, training accuracy = 0.6872\n",
      "Execution time on validation set = 0.32 seconds \n",
      "Validation loss = 0.5546, validation accuracy = 0.7704\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 3 :\n",
      "Execution time on training set = 3.68 seconds \n",
      "Training loss = 0.529, training accuracy = 0.7724\n",
      "Execution time on validation set = 0.31 seconds \n",
      "Validation loss = 0.4965, validation accuracy = 0.7806\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 4 :\n",
      "Execution time on training set = 3.49 seconds \n",
      "Training loss = 0.4936, training accuracy = 0.7875\n",
      "Execution time on validation set = 0.32 seconds \n",
      "Validation loss = 0.4746, validation accuracy = 0.7948\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 5 :\n",
      "Execution time on training set = 3.6 seconds \n",
      "Training loss = 0.4751, training accuracy = 0.7988\n",
      "Execution time on validation set = 0.31 seconds \n",
      "Validation loss = 0.4653, validation accuracy = 0.803\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 6 :\n",
      "Execution time on training set = 3.45 seconds \n",
      "Training loss = 0.4646, training accuracy = 0.7995\n",
      "Execution time on validation set = 0.32 seconds \n",
      "Validation loss = 0.4646, validation accuracy = 0.7969\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 7 :\n",
      "Execution time on training set = 3.66 seconds \n",
      "Training loss = 0.4554, training accuracy = 0.8033\n",
      "Execution time on validation set = 0.3 seconds \n",
      "Validation loss = 0.4585, validation accuracy = 0.805\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 8 :\n",
      "Execution time on training set = 3.57 seconds \n",
      "Training loss = 0.4491, training accuracy = 0.8071\n",
      "Execution time on validation set = 0.29 seconds \n",
      "Validation loss = 0.4522, validation accuracy = 0.8023\n",
      "=======================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-21 12:04:44,357]\u001b[0m Trial 14 finished with value: 0.4521892757519432 and parameters: {'hidden_dim': 59, 'drop_out': 0.47130516213839435, 'learning_rate': 7.32550690657707e-05, 'num_layers': 2}. Best is trial 11 with value: 0.4139311838409175.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================================\n",
      "Epoch 9 :\n",
      "Execution time on training set = 3.64 seconds \n",
      "Training loss = 0.4456, training accuracy = 0.8081\n",
      "Execution time on validation set = 0.33 seconds \n",
      "Validation loss = 0.4525, validation accuracy = 0.8057\n",
      "=======================================================\n",
      "loss at end of trial 14 execution = 0.4521892757519432\n",
      "trial 14 params = {'hidden_dim': 59, 'drop_out': 0.47130516213839435, 'learning_rate': 7.32550690657707e-05, 'num_layers': 2}\n",
      "=======================================================\n",
      "Epoch 0 :\n",
      "Execution time on training set = 11.58 seconds \n",
      "Training loss = 0.5748, training accuracy = 0.6969\n",
      "Execution time on validation set = 0.62 seconds \n",
      "Validation loss = 0.4569, validation accuracy = 0.7976\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 1 :\n",
      "Execution time on training set = 11.51 seconds \n",
      "Training loss = 0.4534, training accuracy = 0.8002\n",
      "Execution time on validation set = 0.56 seconds \n",
      "Validation loss = 0.4438, validation accuracy = 0.8145\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 2 :\n",
      "Execution time on training set = 11.93 seconds \n",
      "Training loss = 0.4317, training accuracy = 0.8112\n",
      "Execution time on validation set = 0.54 seconds \n",
      "Validation loss = 0.4373, validation accuracy = 0.8166\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 3 :\n",
      "Execution time on training set = 11.59 seconds \n",
      "Training loss = 0.414, training accuracy = 0.8199\n",
      "Execution time on validation set = 0.55 seconds \n",
      "Validation loss = 0.4272, validation accuracy = 0.8145\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 4 :\n",
      "Execution time on training set = 11.72 seconds \n",
      "Training loss = 0.3989, training accuracy = 0.8278\n",
      "Execution time on validation set = 0.53 seconds \n",
      "Validation loss = 0.413, validation accuracy = 0.8254\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 5 :\n",
      "Execution time on training set = 12.01 seconds \n",
      "Training loss = 0.3889, training accuracy = 0.8329\n",
      "Execution time on validation set = 0.82 seconds \n",
      "Validation loss = 0.4088, validation accuracy = 0.8247\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 6 :\n",
      "Execution time on training set = 10.79 seconds \n",
      "Training loss = 0.3756, training accuracy = 0.8416\n",
      "Execution time on validation set = 0.51 seconds \n",
      "Validation loss = 0.4363, validation accuracy = 0.8139\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 7 :\n",
      "Execution time on training set = 11.01 seconds \n",
      "Training loss = 0.3656, training accuracy = 0.8449\n",
      "Execution time on validation set = 0.59 seconds \n",
      "Validation loss = 0.4218, validation accuracy = 0.822\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 8 :\n",
      "Execution time on training set = 10.93 seconds \n",
      "Training loss = 0.3486, training accuracy = 0.8523\n",
      "Execution time on validation set = 0.59 seconds \n",
      "Validation loss = 0.466, validation accuracy = 0.8003\n",
      "=======================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-21 12:06:44,242]\u001b[0m Trial 15 finished with value: 0.4088201341421708 and parameters: {'hidden_dim': 141, 'drop_out': 0.4257934114073623, 'learning_rate': 0.0003660548388149779, 'num_layers': 2}. Best is trial 15 with value: 0.4088201341421708.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================================\n",
      "Epoch 9 :\n",
      "Execution time on training set = 10.93 seconds \n",
      "Training loss = 0.3334, training accuracy = 0.8604\n",
      "Execution time on validation set = 0.53 seconds \n",
      "Validation loss = 0.448, validation accuracy = 0.8207\n",
      "=======================================================\n",
      "loss at end of trial 15 execution = 0.4088201341421708\n",
      "trial 15 params = {'hidden_dim': 141, 'drop_out': 0.4257934114073623, 'learning_rate': 0.0003660548388149779, 'num_layers': 2}\n",
      "=======================================================\n",
      "Epoch 0 :\n",
      "Execution time on training set = 17.04 seconds \n",
      "Training loss = 0.5509, training accuracy = 0.7196\n",
      "Execution time on validation set = 0.83 seconds \n",
      "Validation loss = 0.4701, validation accuracy = 0.8043\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 1 :\n",
      "Execution time on training set = 19.34 seconds \n",
      "Training loss = 0.4476, training accuracy = 0.8054\n",
      "Execution time on validation set = 0.77 seconds \n",
      "Validation loss = 0.4475, validation accuracy = 0.8145\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 2 :\n",
      "Execution time on training set = 23.07 seconds \n",
      "Training loss = 0.4261, training accuracy = 0.8145\n",
      "Execution time on validation set = 1.13 seconds \n",
      "Validation loss = 0.4231, validation accuracy = 0.8179\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 3 :\n",
      "Execution time on training set = 19.61 seconds \n",
      "Training loss = 0.4139, training accuracy = 0.8217\n",
      "Execution time on validation set = 0.75 seconds \n",
      "Validation loss = 0.4252, validation accuracy = 0.8179\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 4 :\n",
      "Execution time on training set = 18.55 seconds \n",
      "Training loss = 0.3989, training accuracy = 0.8278\n",
      "Execution time on validation set = 0.83 seconds \n",
      "Validation loss = 0.4157, validation accuracy = 0.8193\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 5 :\n",
      "Execution time on training set = 17.91 seconds \n",
      "Training loss = 0.3888, training accuracy = 0.8342\n",
      "Execution time on validation set = 0.81 seconds \n",
      "Validation loss = 0.4198, validation accuracy = 0.8166\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 6 :\n",
      "Execution time on training set = 18.2 seconds \n",
      "Training loss = 0.3758, training accuracy = 0.8413\n",
      "Execution time on validation set = 0.74 seconds \n",
      "Validation loss = 0.4238, validation accuracy = 0.8159\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 7 :\n",
      "Execution time on training set = 17.5 seconds \n",
      "Training loss = 0.3644, training accuracy = 0.8477\n",
      "Execution time on validation set = 0.65 seconds \n",
      "Validation loss = 0.4153, validation accuracy = 0.8234\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 8 :\n",
      "Execution time on training set = 17.44 seconds \n",
      "Training loss = 0.3534, training accuracy = 0.8518\n",
      "Execution time on validation set = 0.75 seconds \n",
      "Validation loss = 0.4342, validation accuracy = 0.8179\n",
      "=======================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-21 12:09:58,672]\u001b[0m Trial 16 finished with value: 0.415266004593476 and parameters: {'hidden_dim': 208, 'drop_out': 0.44776779471529154, 'learning_rate': 0.0003323928640939741, 'num_layers': 2}. Best is trial 15 with value: 0.4088201341421708.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================================\n",
      "Epoch 9 :\n",
      "Execution time on training set = 17.63 seconds \n",
      "Training loss = 0.3374, training accuracy = 0.8577\n",
      "Execution time on validation set = 0.8 seconds \n",
      "Validation loss = 0.4617, validation accuracy = 0.8145\n",
      "=======================================================\n",
      "loss at end of trial 16 execution = 0.415266004593476\n",
      "trial 16 params = {'hidden_dim': 208, 'drop_out': 0.44776779471529154, 'learning_rate': 0.0003323928640939741, 'num_layers': 2}\n",
      "=======================================================\n",
      "Epoch 0 :\n",
      "Execution time on training set = 44.41 seconds \n",
      "Training loss = 0.6401, training accuracy = 0.626\n",
      "Execution time on validation set = 1.48 seconds \n",
      "Validation loss = 0.5244, validation accuracy = 0.7649\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 1 :\n",
      "Execution time on training set = 39.53 seconds \n",
      "Training loss = 0.4898, training accuracy = 0.7791\n",
      "Execution time on validation set = 1.49 seconds \n",
      "Validation loss = 0.4623, validation accuracy = 0.7928\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 2 :\n",
      "Execution time on training set = 39.16 seconds \n",
      "Training loss = 0.4524, training accuracy = 0.8016\n",
      "Execution time on validation set = 1.45 seconds \n",
      "Validation loss = 0.4462, validation accuracy = 0.8111\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 3 :\n",
      "Execution time on training set = 39.54 seconds \n",
      "Training loss = 0.4412, training accuracy = 0.8076\n",
      "Execution time on validation set = 1.45 seconds \n",
      "Validation loss = 0.4363, validation accuracy = 0.8118\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 4 :\n",
      "Execution time on training set = 40.01 seconds \n",
      "Training loss = 0.4302, training accuracy = 0.8117\n",
      "Execution time on validation set = 1.58 seconds \n",
      "Validation loss = 0.4441, validation accuracy = 0.8077\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 5 :\n",
      "Execution time on training set = 39.25 seconds \n",
      "Training loss = 0.4247, training accuracy = 0.8148\n",
      "Execution time on validation set = 1.51 seconds \n",
      "Validation loss = 0.4307, validation accuracy = 0.8166\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 6 :\n",
      "Execution time on training set = 39.47 seconds \n",
      "Training loss = 0.425, training accuracy = 0.8135\n",
      "Execution time on validation set = 1.48 seconds \n",
      "Validation loss = 0.4309, validation accuracy = 0.82\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 7 :\n",
      "Execution time on training set = 39.44 seconds \n",
      "Training loss = 0.4111, training accuracy = 0.8215\n",
      "Execution time on validation set = 1.5 seconds \n",
      "Validation loss = 0.4289, validation accuracy = 0.8139\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 8 :\n",
      "Execution time on training set = 39.43 seconds \n",
      "Training loss = 0.4077, training accuracy = 0.8211\n",
      "Execution time on validation set = 1.43 seconds \n",
      "Validation loss = 0.4289, validation accuracy = 0.8166\n",
      "=======================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-21 12:16:53,570]\u001b[0m Trial 17 finished with value: 0.42890717542689777 and parameters: {'hidden_dim': 413, 'drop_out': 0.6087376906782147, 'learning_rate': 7.340413957270389e-05, 'num_layers': 2}. Best is trial 15 with value: 0.4088201341421708.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================================\n",
      "Epoch 9 :\n",
      "Execution time on training set = 39.69 seconds \n",
      "Training loss = 0.4014, training accuracy = 0.8309\n",
      "Execution time on validation set = 1.52 seconds \n",
      "Validation loss = 0.4341, validation accuracy = 0.8186\n",
      "=======================================================\n",
      "loss at end of trial 17 execution = 0.42890717542689777\n",
      "trial 17 params = {'hidden_dim': 413, 'drop_out': 0.6087376906782147, 'learning_rate': 7.340413957270389e-05, 'num_layers': 2}\n",
      "=======================================================\n",
      "Epoch 0 :\n",
      "Execution time on training set = 26.05 seconds \n",
      "Training loss = 0.6903, training accuracy = 0.5582\n",
      "Execution time on validation set = 1.14 seconds \n",
      "Validation loss = 0.6883, validation accuracy = 0.572\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 1 :\n",
      "Execution time on training set = 25.96 seconds \n",
      "Training loss = 0.687, training accuracy = 0.5704\n",
      "Execution time on validation set = 1.09 seconds \n",
      "Validation loss = 0.6846, validation accuracy = 0.57\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 2 :\n",
      "Execution time on training set = 27.59 seconds \n",
      "Training loss = 0.683, training accuracy = 0.5696\n",
      "Execution time on validation set = 1.11 seconds \n",
      "Validation loss = 0.6811, validation accuracy = 0.57\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 3 :\n",
      "Execution time on training set = 27.84 seconds \n",
      "Training loss = 0.6794, training accuracy = 0.5691\n",
      "Execution time on validation set = 1.11 seconds \n",
      "Validation loss = 0.6758, validation accuracy = 0.5747\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 4 :\n",
      "Execution time on training set = 28.06 seconds \n",
      "Training loss = 0.6741, training accuracy = 0.5699\n",
      "Execution time on validation set = 1.12 seconds \n",
      "Validation loss = 0.6692, validation accuracy = 0.5781\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 5 :\n",
      "Execution time on training set = 32.26 seconds \n",
      "Training loss = 0.6673, training accuracy = 0.5709\n",
      "Execution time on validation set = 1.25 seconds \n",
      "Validation loss = 0.661, validation accuracy = 0.5761\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 6 :\n",
      "Execution time on training set = 34.77 seconds \n",
      "Training loss = 0.6577, training accuracy = 0.5745\n",
      "Execution time on validation set = 1.03 seconds \n",
      "Validation loss = 0.6478, validation accuracy = 0.5829\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 7 :\n",
      "Execution time on training set = 32.06 seconds \n",
      "Training loss = 0.6427, training accuracy = 0.6012\n",
      "Execution time on validation set = 1.34 seconds \n",
      "Validation loss = 0.6286, validation accuracy = 0.6168\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 8 :\n",
      "Execution time on training set = 29.02 seconds \n",
      "Training loss = 0.6202, training accuracy = 0.6664\n",
      "Execution time on validation set = 1.1 seconds \n",
      "Validation loss = 0.6042, validation accuracy = 0.7208\n",
      "=======================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-21 12:21:58,192]\u001b[0m Trial 18 finished with value: 0.581594705581665 and parameters: {'hidden_dim': 293, 'drop_out': 0.49969364726309784, 'learning_rate': 5.710101433869957e-06, 'num_layers': 2}. Best is trial 15 with value: 0.4088201341421708.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================================\n",
      "Epoch 9 :\n",
      "Execution time on training set = 29.47 seconds \n",
      "Training loss = 0.5957, training accuracy = 0.7316\n",
      "Execution time on validation set = 1.2 seconds \n",
      "Validation loss = 0.5816, validation accuracy = 0.7711\n",
      "=======================================================\n",
      "loss at end of trial 18 execution = 0.581594705581665\n",
      "trial 18 params = {'hidden_dim': 293, 'drop_out': 0.49969364726309784, 'learning_rate': 5.710101433869957e-06, 'num_layers': 2}\n",
      "=======================================================\n",
      "Epoch 0 :\n",
      "Execution time on training set = 7.93 seconds \n",
      "Training loss = 0.68, training accuracy = 0.5696\n",
      "Execution time on validation set = 0.53 seconds \n",
      "Validation loss = 0.671, validation accuracy = 0.5713\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 1 :\n",
      "Execution time on training set = 9.84 seconds \n",
      "Training loss = 0.6543, training accuracy = 0.5998\n",
      "Execution time on validation set = 0.46 seconds \n",
      "Validation loss = 0.6185, validation accuracy = 0.6923\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 2 :\n",
      "Execution time on training set = 8.41 seconds \n",
      "Training loss = 0.5735, training accuracy = 0.7447\n",
      "Execution time on validation set = 0.42 seconds \n",
      "Validation loss = 0.519, validation accuracy = 0.7765\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 3 :\n",
      "Execution time on training set = 7.76 seconds \n",
      "Training loss = 0.5076, training accuracy = 0.776\n",
      "Execution time on validation set = 0.43 seconds \n",
      "Validation loss = 0.4798, validation accuracy = 0.7948\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 4 :\n",
      "Execution time on training set = 8.21 seconds \n",
      "Training loss = 0.4808, training accuracy = 0.7918\n",
      "Execution time on validation set = 0.47 seconds \n",
      "Validation loss = 0.4651, validation accuracy = 0.7996\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 5 :\n",
      "Execution time on training set = 8.44 seconds \n",
      "Training loss = 0.4645, training accuracy = 0.7985\n",
      "Execution time on validation set = 0.48 seconds \n",
      "Validation loss = 0.4494, validation accuracy = 0.8057\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 6 :\n",
      "Execution time on training set = 8.68 seconds \n",
      "Training loss = 0.4562, training accuracy = 0.802\n",
      "Execution time on validation set = 0.45 seconds \n",
      "Validation loss = 0.4477, validation accuracy = 0.8057\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 7 :\n",
      "Execution time on training set = 7.97 seconds \n",
      "Training loss = 0.4482, training accuracy = 0.8074\n",
      "Execution time on validation set = 0.47 seconds \n",
      "Validation loss = 0.4439, validation accuracy = 0.8111\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 8 :\n",
      "Execution time on training set = 8.36 seconds \n",
      "Training loss = 0.4436, training accuracy = 0.8092\n",
      "Execution time on validation set = 0.46 seconds \n",
      "Validation loss = 0.4454, validation accuracy = 0.8139\n",
      "=======================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-10-21 12:23:28,243]\u001b[0m Trial 19 finished with value: 0.44119557867879455 and parameters: {'hidden_dim': 78, 'drop_out': 0.408664793417039, 'learning_rate': 6.0295282448095977e-05, 'num_layers': 2}. Best is trial 15 with value: 0.4088201341421708.\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================================\n",
      "Epoch 9 :\n",
      "Execution time on training set = 9.82 seconds \n",
      "Training loss = 0.4385, training accuracy = 0.8084\n",
      "Execution time on validation set = 0.41 seconds \n",
      "Validation loss = 0.4412, validation accuracy = 0.8132\n",
      "=======================================================\n",
      "loss at end of trial 19 execution = 0.44119557867879455\n",
      "trial 19 params = {'hidden_dim': 78, 'drop_out': 0.408664793417039, 'learning_rate': 6.0295282448095977e-05, 'num_layers': 2}\n",
      "Best trial:\n",
      "{'hidden_dim': 141, 'drop_out': 0.4257934114073623, 'learning_rate': 0.0003660548388149779, 'num_layers': 2}\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('fastai': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 36.855353,
   "end_time": "2021-09-24T11:30:04.367162",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-24T11:29:27.511809",
   "version": "2.3.3"
  },
  "interpreter": {
   "hash": "2ff06204c0662b9359ef4233b0e8cfcc016e07736dbe455d1edaa8487878aae2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}