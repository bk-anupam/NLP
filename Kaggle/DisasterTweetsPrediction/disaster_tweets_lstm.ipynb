{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from nltk.tokenize import RegexpTokenizer\r\n",
    "from nltk.stem.snowball import SnowballStemmer\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\r\n",
    "from sklearn.naive_bayes import ComplementNB\r\n",
    "from sklearn.model_selection import cross_validate\r\n",
    "\r\n",
    "df_train = pd.read_csv('./data/train.csv')\r\n",
    "df_test = pd.read_csv('./data/test.csv')\r\n",
    "print(f\"Rows in train.csv = {len(df_train)}\")\r\n",
    "print(f\"Rows in test.csv = {len(df_test)}\")\r\n",
    "pd.set_option('display.max_colwidth', None)\r\n",
    "df_train.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Rows in train.csv = 7613\n",
      "Rows in test.csv = 3263\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation orders in California</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location  \\\n",
       "0   1     NaN      NaN   \n",
       "1   4     NaN      NaN   \n",
       "2   5     NaN      NaN   \n",
       "3   6     NaN      NaN   \n",
       "4   7     NaN      NaN   \n",
       "\n",
       "                                                                                                                                    text  \\\n",
       "0                                                                  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all   \n",
       "1                                                                                                 Forest fire near La Ronge Sask. Canada   \n",
       "2  All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected   \n",
       "3                                                                      13,000 people receive #wildfires evacuation orders in California    \n",
       "4                                               Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school    \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-24T11:29:35.989692Z",
     "iopub.status.busy": "2021-09-24T11:29:35.988494Z",
     "iopub.status.idle": "2021-09-24T11:29:37.721542Z",
     "shell.execute_reply": "2021-09-24T11:29:37.720795Z",
     "shell.execute_reply.started": "2021-09-24T11:25:43.524893Z"
    },
    "papermill": {
     "duration": 1.765907,
     "end_time": "2021-09-24T11:29:37.721745",
     "exception": false,
     "start_time": "2021-09-24T11:29:35.955838",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df_train_pos = df_train[df_train.target == 1]\r\n",
    "df_train_neg = df_train[df_train.target == 0]\r\n",
    "print(f\"No. of positive training examples = {len(df_train_pos)}\")\r\n",
    "print(f\"No. of negative training examples = {len(df_train_neg)}\")\r\n",
    "train_keywords_unique = df_train.keyword.unique()\r\n",
    "print(f\"No. of unique keywords = {len(train_keywords_unique)}\")\r\n",
    "df_train_notnull_keywords = df_train[~df_train.keyword.isnull()]\r\n",
    "print(f\"No of train examples with keyword not null = {len(df_train_notnull_keywords)}\")\r\n",
    "df_train_notnull_keywords.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No. of positive training examples = 3271\n",
      "No. of negative training examples = 4342\n",
      "No. of unique keywords = 222\n",
      "No of train examples with keyword not null = 7552\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>48</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>@bbcmtd Wholesale Markets ablaze http://t.co/lHYXEOHY6C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>49</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Est. September 2012 - Bristol</td>\n",
       "      <td>We always try to bring the heavy. #metal #RT http://t.co/YAo1e0xngw</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>50</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>#AFRICANBAZE: Breaking news:Nigeria flag set ablaze in Aba. http://t.co/2nndBGwyEi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>52</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Crying out for more! Set me ablaze</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>53</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>London, UK</td>\n",
       "      <td>On plus side LOOK AT THE SKY LAST NIGHT IT WAS ABLAZE http://t.co/qqsmshaJ3N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id keyword                       location  \\\n",
       "31  48  ablaze                     Birmingham   \n",
       "32  49  ablaze  Est. September 2012 - Bristol   \n",
       "33  50  ablaze                         AFRICA   \n",
       "34  52  ablaze               Philadelphia, PA   \n",
       "35  53  ablaze                     London, UK   \n",
       "\n",
       "                                                                                  text  \\\n",
       "31                             @bbcmtd Wholesale Markets ablaze http://t.co/lHYXEOHY6C   \n",
       "32                 We always try to bring the heavy. #metal #RT http://t.co/YAo1e0xngw   \n",
       "33  #AFRICANBAZE: Breaking news:Nigeria flag set ablaze in Aba. http://t.co/2nndBGwyEi   \n",
       "34                                                  Crying out for more! Set me ablaze   \n",
       "35        On plus side LOOK AT THE SKY LAST NIGHT IT WAS ABLAZE http://t.co/qqsmshaJ3N   \n",
       "\n",
       "    target  \n",
       "31       1  \n",
       "32       0  \n",
       "33       1  \n",
       "34       0  \n",
       "35       0  "
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-24T11:29:37.787808Z",
     "iopub.status.busy": "2021-09-24T11:29:37.787078Z",
     "iopub.status.idle": "2021-09-24T11:29:37.822364Z",
     "shell.execute_reply": "2021-09-24T11:29:37.821464Z",
     "shell.execute_reply.started": "2021-09-24T11:25:45.378728Z"
    },
    "papermill": {
     "duration": 0.071705,
     "end_time": "2021-09-24T11:29:37.822571",
     "exception": false,
     "start_time": "2021-09-24T11:29:37.750866",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df_test.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, stay safe everyone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location  \\\n",
       "0   0     NaN      NaN   \n",
       "1   2     NaN      NaN   \n",
       "2   3     NaN      NaN   \n",
       "3   9     NaN      NaN   \n",
       "4  11     NaN      NaN   \n",
       "\n",
       "                                                                                               text  \n",
       "0                                                                Just happened a terrible car crash  \n",
       "1                                  Heard about #earthquake is different cities, stay safe everyone.  \n",
       "2  there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all  \n",
       "3                                                          Apocalypse lighting. #Spokane #wildfires  \n",
       "4                                                     Typhoon Soudelor kills 28 in China and Taiwan  "
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-24T11:29:37.892195Z",
     "iopub.status.busy": "2021-09-24T11:29:37.891301Z",
     "iopub.status.idle": "2021-09-24T11:29:37.894938Z",
     "shell.execute_reply": "2021-09-24T11:29:37.895466Z",
     "shell.execute_reply.started": "2021-09-24T11:25:45.423964Z"
    },
    "papermill": {
     "duration": 0.043933,
     "end_time": "2021-09-24T11:29:37.895658",
     "exception": false,
     "start_time": "2021-09-24T11:29:37.851725",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preprocess the tweets "
   ],
   "metadata": {
    "papermill": {
     "duration": 0.029155,
     "end_time": "2021-09-24T11:29:37.954056",
     "exception": false,
     "start_time": "2021-09-24T11:29:37.924901",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from nltk.stem import WordNetLemmatizer\r\n",
    "from nltk.tokenize import TweetTokenizer\r\n",
    "import string\r\n",
    "import re\r\n",
    "\r\n",
    "punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~`\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\r\n",
    "def clean_special_chars(text, punct):\r\n",
    "    for p in punct:\r\n",
    "        text = text.replace(p, ' ')\r\n",
    "    return text\r\n",
    "\r\n",
    "def process_tweet(df, text, keyword):\r\n",
    "    lemmatizer = WordNetLemmatizer()    \r\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)    \r\n",
    "    processed_text = []\r\n",
    "    stop = stopwords.words(\"english\")\r\n",
    "    for tweet, keyword in zip(df[text], df[keyword]):\r\n",
    "        tweets_clean = []        \r\n",
    "        # remove stock market tickers like $GE\r\n",
    "        #tweet = tweet + \" \" + keyword\r\n",
    "        tweet = re.sub(r'\\$\\w*', '', tweet)\r\n",
    "        # remove old style retweet text \"RT\"\r\n",
    "        tweet = re.sub(r'^RT[\\s]+', '', tweet)\r\n",
    "        # remove hyperlinks\r\n",
    "        tweet = re.sub(r'http\\S+', '', tweet)\r\n",
    "        # remove hashtags\r\n",
    "        # only removing the hash #, @, ... sign from the word\r\n",
    "        tweet = re.sub(r'\\.{3}|@|#', '', tweet)    \r\n",
    "        tweet = clean_special_chars(tweet, punct)\r\n",
    "        # remove junk characters which don't have an ascii code\r\n",
    "        tweet = tweet.encode(\"ascii\", \"ignore\").decode(\"utf-8\", \"ignore\")\r\n",
    "        # tokenize tweets        \r\n",
    "        tweet_tokens = tokenizer.tokenize(tweet)\r\n",
    "        for word in tweet_tokens:\r\n",
    "            # remove stopwords and punctuation\r\n",
    "            if (word.isalpha() and len(word) > 2 and word not in stop \r\n",
    "                and word not in string.punctuation):\r\n",
    "                #stem_word = stemmer.stem(word)  # stemming word            \r\n",
    "                lem_word = lemmatizer.lemmatize(word)\r\n",
    "                tweets_clean.append(lem_word) \r\n",
    "        processed_text.append(\" \".join(tweets_clean))        \r\n",
    "    df['processed_text'] = np.array(processed_text)"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-24T11:29:43.429967Z",
     "iopub.status.busy": "2021-09-24T11:29:43.429217Z",
     "iopub.status.idle": "2021-09-24T11:29:43.432488Z",
     "shell.execute_reply": "2021-09-24T11:29:43.431898Z",
     "shell.execute_reply.started": "2021-09-24T11:25:50.679824Z"
    },
    "papermill": {
     "duration": 0.044876,
     "end_time": "2021-09-24T11:29:43.432656",
     "exception": false,
     "start_time": "2021-09-24T11:29:43.387780",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df_train[\"keyword\"] = df_train[\"keyword\"].fillna(\"no_keyword\")\r\n",
    "df_test[\"keyword\"] = df_test[\"keyword\"].fillna(\"no_keyword\")\r\n",
    "process_tweet(df_train, 'text', \"keyword\")\r\n",
    "process_tweet(df_test, 'text', \"keyword\")\r\n",
    "df_train[\"prcsd_tweet_len\"] = df_train[\"processed_text\"].apply(lambda row: len(row.split()))\r\n",
    "df_test[\"prcsd_tweet_len\"] = df_test[\"processed_text\"].apply(lambda row: len(row.split()))"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-24T11:29:43.494947Z",
     "iopub.status.busy": "2021-09-24T11:29:43.493949Z",
     "iopub.status.idle": "2021-09-24T11:29:48.131903Z",
     "shell.execute_reply": "2021-09-24T11:29:48.132422Z",
     "shell.execute_reply.started": "2021-09-24T11:25:50.692578Z"
    },
    "papermill": {
     "duration": 4.670808,
     "end_time": "2021-09-24T11:29:48.132640",
     "exception": false,
     "start_time": "2021-09-24T11:29:43.461832",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df_train[\"prcsd_tweet_len\"].mean()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8.744384605280441"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "df_train.iloc[50:52, :]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>prcsd_tweet_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>73</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Sheffield Township, Ohio</td>\n",
       "      <td>Deputies: Man shot before Brighton home set ablaze http://t.co/gWNRhMSO8k</td>\n",
       "      <td>1</td>\n",
       "      <td>deputy man shot brighton home set ablaze</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>74</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>India</td>\n",
       "      <td>Man wife get six years jail for setting ablaze niece\\nhttp://t.co/eV1ahOUCZA</td>\n",
       "      <td>1</td>\n",
       "      <td>man wife get six year jail setting ablaze niece</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id keyword                  location  \\\n",
       "50  73  ablaze  Sheffield Township, Ohio   \n",
       "51  74  ablaze                     India   \n",
       "\n",
       "                                                                            text  \\\n",
       "50     Deputies: Man shot before Brighton home set ablaze http://t.co/gWNRhMSO8k   \n",
       "51  Man wife get six years jail for setting ablaze niece\\nhttp://t.co/eV1ahOUCZA   \n",
       "\n",
       "    target                                   processed_text  prcsd_tweet_len  \n",
       "50       1         deputy man shot brighton home set ablaze                7  \n",
       "51       1  man wife get six year jail setting ablaze niece                9  "
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-24T11:29:48.195063Z",
     "iopub.status.busy": "2021-09-24T11:29:48.194413Z",
     "iopub.status.idle": "2021-09-24T11:29:48.207920Z",
     "shell.execute_reply": "2021-09-24T11:29:48.208468Z",
     "shell.execute_reply.started": "2021-09-24T11:25:55.413845Z"
    },
    "papermill": {
     "duration": 0.046078,
     "end_time": "2021-09-24T11:29:48.208659",
     "exception": false,
     "start_time": "2021-09-24T11:29:48.162581",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "\r\n",
    "df_test.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>prcsd_tweet_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>happened terrible car crash</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, stay safe everyone.</td>\n",
       "      <td>heard earthquake different city stay safe everyone</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all</td>\n",
       "      <td>forest fire spot pond goose fleeing across street cannot save</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>apocalypse lighting spokane wildfire</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>typhoon soudelor kill china taiwan</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     keyword location  \\\n",
       "0   0  no_keyword      NaN   \n",
       "1   2  no_keyword      NaN   \n",
       "2   3  no_keyword      NaN   \n",
       "3   9  no_keyword      NaN   \n",
       "4  11  no_keyword      NaN   \n",
       "\n",
       "                                                                                               text  \\\n",
       "0                                                                Just happened a terrible car crash   \n",
       "1                                  Heard about #earthquake is different cities, stay safe everyone.   \n",
       "2  there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all   \n",
       "3                                                          Apocalypse lighting. #Spokane #wildfires   \n",
       "4                                                     Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "\n",
       "                                                  processed_text  \\\n",
       "0                                    happened terrible car crash   \n",
       "1             heard earthquake different city stay safe everyone   \n",
       "2  forest fire spot pond goose fleeing across street cannot save   \n",
       "3                           apocalypse lighting spokane wildfire   \n",
       "4                             typhoon soudelor kill china taiwan   \n",
       "\n",
       "   prcsd_tweet_len  \n",
       "0                4  \n",
       "1                7  \n",
       "2               10  \n",
       "3                4  \n",
       "4                5  "
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-24T11:29:48.271874Z",
     "iopub.status.busy": "2021-09-24T11:29:48.271196Z",
     "iopub.status.idle": "2021-09-24T11:29:48.285535Z",
     "shell.execute_reply": "2021-09-24T11:29:48.284912Z",
     "shell.execute_reply.started": "2021-09-24T11:25:55.431885Z"
    },
    "papermill": {
     "duration": 0.046942,
     "end_time": "2021-09-24T11:29:48.285685",
     "exception": false,
     "start_time": "2021-09-24T11:29:48.238743",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Let us try some deep learning techniques now"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def get_word_embedding_dict(embedding_file_path):\r\n",
    "    embedding_dict = {}\r\n",
    "    with open(embedding_file_path, \"r\") as f:\r\n",
    "        # https://stackoverflow.com/questions/8009882/how-to-read-a-large-file-line-by-line\r\n",
    "        for line in f:\r\n",
    "            values = line.split()\r\n",
    "            word = values[0]\r\n",
    "            word_vec = np.asarray(values[1:], \"float32\")\r\n",
    "            embedding_dict[word] = word_vec\r\n",
    "    return embedding_dict        \r\n",
    "\r\n",
    "#glove_embedding_dict = get_word_embedding_dict(\"../../../glove.twitter.27B/glove.twitter.27B.200d.txt\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import torchtext\r\n",
    "\r\n",
    "glove_emb = torchtext.vocab.GloVe(name=\"twitter.27B\", dim=200)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# build tweets vocab from training data\r\n",
    "\r\n",
    "from torchtext.vocab import build_vocab_from_iterator\r\n",
    "\r\n",
    "def yield_tokens(df):\r\n",
    "    for index, row in df.iterrows():\r\n",
    "        yield row[\"processed_text\"].split()\r\n",
    "    \r\n",
    "tweet_vocab = build_vocab_from_iterator(yield_tokens(df_train), specials=[\"<unk>\", \"<pad>\"])    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "\r\n",
    "# For the problem specific vocab, get the embedding vectors from the pre-trained embedding\r\n",
    "# for each word in vocab and return a matrix of shape vocab_size, embedding_dim. This matrix\r\n",
    "# will be the pretrained embedding weight matrix which we will use to create the embedding layer\r\n",
    "def get_vocab_pt_emb_matrix(text_vocab, emb):\r\n",
    "    embedding_matrix = []\r\n",
    "    for token in text_vocab.get_itos():\r\n",
    "        embedding_matrix.append(emb[token])\r\n",
    "    return torch.stack(embedding_matrix)\r\n",
    "\r\n",
    "pt_emb_weights = get_vocab_pt_emb_matrix(tweet_vocab, glove_emb)\r\n",
    "pt_emb_layer = nn.Embedding.from_pretrained(pt_emb_weights)\r\n",
    "#result = pt_emb_layer(torch.LongTensor([1,2]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "glove_emb[\"<pad>\"]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# [(index, token) for index, token in enumerate(glove_emb.itos) if token == \"<unk>\"]\r\n",
    "#pt_emb_layer(torch.LongTensor([1]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\r\n",
    "\r\n",
    "df_train[\"vectorized_tweet\"] = df_train[\"processed_text\"].apply(\r\n",
    "    lambda row:torch.LongTensor(tweet_vocab.lookup_indices(row.split()))\r\n",
    "    )\r\n",
    "\r\n",
    "#x_seq = df_train[\"vectorized_tweet\"].values.tolist()\r\n",
    "# the index for 'pad' token in tweet_vocab is 1.\r\n",
    "#x_padded_seq = pad_sequence(x_seq, batch_first=True, padding_value=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "from torch.utils.data import Dataset, DataLoader\r\n",
    "\r\n",
    "class VectorizedTweetDataSet(Dataset):\r\n",
    "    def __init__(self, tweet_vecs, labels):\r\n",
    "        self.tweet_vecs = tweet_vecs\r\n",
    "        self.labels = labels\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.labels)\r\n",
    "\r\n",
    "    def __getitem__(self, idx):\r\n",
    "        tweet_vec = self.tweet_vecs[idx]\r\n",
    "        label = self.labels[idx]\r\n",
    "        tweet_len = len(tweet_vec)\r\n",
    "        return (tweet_vec, label)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "# If the goal is to train with mini-batches, one needs to pad the sequences in each batch. \r\n",
    "# In other words, given a mini-batch of size N, if the length of the largest sequence is L, \r\n",
    "# one needs to pad every sequence with a length of smaller than L with zeros and make their \r\n",
    "# lengths equal to L. Moreover, it is important that the sequences in the batch are in the \r\n",
    "# descending order.\r\n",
    "def pad_collate(batch):\r\n",
    "    # Each element in the batch is a tuple (data, label)\r\n",
    "    # sort the batch (based on tweet word count) in descending order\r\n",
    "    sorted_batch = sorted(batch, key=lambda x:x[0].shape[0], reverse=True)\r\n",
    "    sequences = [x[0] for x in sorted_batch]\r\n",
    "    sequences_padded = pad_sequence(sequences, batch_first=True, padding_value=0)\r\n",
    "    # Also need to store the length of each sequence.This is later needed in order to unpad \r\n",
    "    # the sequences\r\n",
    "    seq_len = torch.Tensor([len(x) for x in sequences])\r\n",
    "    labels = torch.Tensor([x[1] for x in sorted_batch])\r\n",
    "    return sequences_padded, seq_len, labels\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "from torch.utils.data import Subset\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "tweet_ds = VectorizedTweetDataSet(df_train[\"vectorized_tweet\"].values, df_train[\"target\"].values)\r\n",
    "# split the tweet_ds into train and validation datasets with 80:20 ratio\r\n",
    "train_idx, val_idx = train_test_split(list(range(len(tweet_ds))), test_size=0.2, random_state=42)\r\n",
    "train_ds = Subset(tweet_ds, train_idx)\r\n",
    "val_ds = Subset(tweet_ds, val_idx)\r\n",
    "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True, collate_fn=pad_collate)\r\n",
    "val_dl = DataLoader(val_ds, batch_size=64, shuffle=True, collate_fn=pad_collate)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torch.nn import functional as F\r\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\r\n",
    "\r\n",
    "class DisasterModel(nn.Module):\r\n",
    "    \"\"\"The RNN model.\"\"\"\r\n",
    "    def __init__(self, vocab_size, num_layers, is_bidirect, emb_dim, hidden_dim, out_dim, \r\n",
    "                drop_prob=0.5, **kwargs):\r\n",
    "        super(DisasterModel, self).__init__(**kwargs)\r\n",
    "        \r\n",
    "        self.vocab_size = vocab_size\r\n",
    "        self.num_layers = num_layers        \r\n",
    "        self.emb_dim = emb_dim\r\n",
    "        self.hidden_dim = hidden_dim        \r\n",
    "        self.output_dim = out_dim        \r\n",
    "        # Embedding layer\r\n",
    "        self.emb_layer = nn.Embedding(self.vocab_size, emb_dim)\r\n",
    "        # LSTM Layer        \r\n",
    "        self.lstm_layer = nn.LSTM(\r\n",
    "                        input_size=emb_dim, hidden_size=hidden_dim, batch_first=True, \r\n",
    "                        bidirectional=is_bidirect, num_layers=num_layers, dropout=drop_prob\r\n",
    "                        )\r\n",
    "        self.dropout = nn.Dropout(p = drop_prob)                        \r\n",
    "        \r\n",
    "        # If the RNN is bidirectional `num_directions` should be 2, else it should be 1.        \r\n",
    "        if not is_bidirect:\r\n",
    "            self.num_directions = 1\r\n",
    "            # The linear layer is for making predictions \r\n",
    "            # input to linear output layer is of shape num_steps, batch_size, num_hiddens\r\n",
    "            # and output is of shape num_steps, batch_size, vocab_size\r\n",
    "            # Wya is of shape (vocab_size, num_hiddens), a_out is of shape (num_hiddens, 1)\r\n",
    "            # yt_pred = np.dot(Wya, a_out) + b is of shape (vocab_size, 1)\r\n",
    "            # replace 1 with m (batch_size) and add num_steps as the first dimension to have\r\n",
    "            # vectorized form of the output\r\n",
    "            self.linear = nn.Linear(self.hidden_dim, self.output_dim)\r\n",
    "        else:       \r\n",
    "            self.num_directions = 2     \r\n",
    "            self.linear = nn.Linear(self.hidden_dim * 2, self.output_dim)\r\n",
    "        # The activation layer which converts output to 0 or 1            \r\n",
    "        self.act = nn.Sigmoid()            \r\n",
    "\r\n",
    "    def forward(self, inputs, input_lengths, state):        \r\n",
    "        # inputs is of shape batch_size, num_steps(sequence length which is the length of\r\n",
    "        # longest text sequence). Each row of inputs is 1d LongTensor array of length \r\n",
    "        # num_steps containing word index. Using the embedding layer we want to convert\r\n",
    "        # each word index to its corresponding word vector of dimension emb_dim\r\n",
    "        batch_size = inputs.size(0)\r\n",
    "        num_steps = inputs.size(1)        \r\n",
    "        # embeds is of shape batch_size * num_steps * emb_dim and is the input to lstm layer\r\n",
    "        embeds = self.emb_layer(inputs)        \r\n",
    "        # pack_padded_sequence before feeding into LSTM. This is required so pytorch knows\r\n",
    "        # which elements of the sequence are padded ones and ignore them in computation.\r\n",
    "        # This step is done only after the embedding step\r\n",
    "        embeds_pack = pack_padded_sequence(embeds, input_lengths, batch_first=True)\r\n",
    "        # lstm_out is of shape batch_size * num_steps * hidden_size and contains the output\r\n",
    "        # features (h_t) from the last layer of LSTM for each t\r\n",
    "        # h_n is of shape num_layers * batch_size * hidden_size and contains the final hidden \r\n",
    "        # state for each element in the batch i.e. hidden state at t_end\r\n",
    "        # same for c_n as h_n except that it is the final cell state\r\n",
    "        lstm_out_pack, (h_n, c_n) = self.lstm_layer(embeds_pack)\r\n",
    "        # unpack the output\r\n",
    "        lstm_out, lstm_out_len = pad_packed_sequence(lstm_out_pack, batch_first=True)        \r\n",
    "        # tensor flattening works only if tensor is contiguous\r\n",
    "        # https://discuss.pytorch.org/t/contigious-vs-non-contigious-tensor/30107/2\r\n",
    "        # flatten lstm_out from 3d to 2d with shape (batch_size * num_steps), hidden_dim)\r\n",
    "        # lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)        \r\n",
    "        lstm_out = h_n[-1, :, :]\r\n",
    "        #print(f\"h_n.shape = {h_n.shape}\")\r\n",
    "        #print(f\"h_n = {h_n[1, 0, :]}\")\r\n",
    "        #print(f\"lstm_out.shape = {lstm_out.shape}\")\r\n",
    "        #print(f\"lstm_out_len = {lstm_out_len}\")\r\n",
    "        #print(f\"lstm_out = {lstm_out}\")\r\n",
    "        # regularize lstm output by applying dropout\r\n",
    "        out = self.dropout(lstm_out)        \r\n",
    "        # The the output Y of fully connected rnn layer has the shape of \r\n",
    "        # (`num_steps` * `batch_size`, `num_hiddens`). This Y is then fed as input to the \r\n",
    "        # output fully connected linear layer which produces the prediction in the output shape of \r\n",
    "        # (`num_steps` * `batch_size`, `output_dim`).        \r\n",
    "        output = self.linear(out)\r\n",
    "        #print(f\"output.shape = {output.shape}\")\r\n",
    "        #print(f\"output = {output}\")\r\n",
    "        # reshape output to batch_size, num_steps, output_dim\r\n",
    "        #output = output.view(batch_size, -1, self.output_dim)\r\n",
    "        #print(f\"output.shape = {output.shape}\")\r\n",
    "        #print(f\"output = {output}\")\r\n",
    "        # reshape output again to batch_size, output_dim. The last element of middle dimension\r\n",
    "        # i.e. num_steps is taken i.e. for each item in the batch the output is the hidden state\r\n",
    "        # from the last layer of LSTM for t = t_end\r\n",
    "        #output = output[:, -1, :]\r\n",
    "        output = self.act(output)\r\n",
    "        return output, (h_n, c_n)\r\n",
    "\r\n",
    "    def init_state(self, device, batch_size=1):\r\n",
    "        \"\"\" Initialize the hidden state i.e. initialize all the neurons in all the hidden layers \r\n",
    "        to zero\"\"\"\r\n",
    "        if not isinstance(self.lstm_layer, nn.LSTM):\r\n",
    "            # `nn.GRU` takes a tensor as hidden state\r\n",
    "            return torch.zeros((self.num_directions * self.num_layers,\r\n",
    "                                batch_size, self.hidden_dim), device=device)\r\n",
    "        else:\r\n",
    "            # `nn.LSTM` takes a tuple of hidden states (h0, c0). h0 = initial\r\n",
    "            # hidden state for each element in the batch, c0 = initial cell state\r\n",
    "            # for each element in the batch\r\n",
    "            return (torch.zeros((self.num_directions * self.num_layers,\r\n",
    "                                 batch_size, self.hidden_dim), device=device),\r\n",
    "                    torch.zeros((self.num_directions * self.num_layers,\r\n",
    "                                 batch_size, self.hidden_dim), device=device))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    "# Dimensions of various layers and other parameters to model\r\n",
    "vocab_size = len(tweet_vocab)\r\n",
    "emb_dim = 200\r\n",
    "hidden_dim = 256\r\n",
    "out_dim = 1\r\n",
    "num_layers = 2\r\n",
    "is_bidirectional = False\r\n",
    "drop_out_prob = 0.5 \r\n",
    "\r\n",
    "model = DisasterModel(vocab_size = vocab_size, num_layers = num_layers, is_bidirect = is_bidirectional,  \r\n",
    "                emb_dim = emb_dim, hidden_dim = hidden_dim, out_dim = out_dim, \r\n",
    "                drop_prob = drop_out_prob)\r\n",
    "\r\n",
    "# copy the vocab specific weights(emb vectors) from pretrained embeddings to model embedding layer\r\n",
    "model.emb_layer.weight.data.copy_(pt_emb_weights)                \r\n",
    "print(model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DisasterModel(\n",
      "  (emb_layer): Embedding(14568, 200)\n",
      "  (lstm_layer): LSTM(200, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (linear): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (act): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "source": [
    "import torch.optim as optim\r\n",
    "learning_rate = 0.001\r\n",
    "# define the optimizer ( we choose mini batch gradient descent with momentum)\r\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\r\n",
    "# loss function\r\n",
    "loss_fn = nn.BCELoss()\r\n",
    "batch_size = 64\r\n",
    "grad_clip = 5\r\n",
    "\r\n",
    "# metric to measure model performance\r\n",
    "def accuracy(y_pred, y):\r\n",
    "    # y_pred is in the range 0 to 1. Convert it to 0 or 1 by rounding\r\n",
    "    y_pred_round = torch.round(y_pred.squeeze())\r\n",
    "    correct = (y_pred_round == y.squeeze()).float()\r\n",
    "    acc = correct.sum() / len(correct)\r\n",
    "    return acc\r\n",
    "\r\n",
    "acc = accuracy    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "source": [
    "def train_epoch(dl, init_hidden, model, loss_fn, optimizer, accuracy, device, batch_size):\r\n",
    "    batch_count = 0\r\n",
    "    loss_epoch = []\r\n",
    "    acc_epoch = []    \r\n",
    "    for inputs, input_lengths, labels in dl:\r\n",
    "        # create a new hidden state instance for each minibatch to avoid long gradient chains\r\n",
    "        # involving all previous minibatches of an epoch\r\n",
    "        h = tuple([e.data for e in init_hidden])\r\n",
    "        inputs,input_lengths,labels = inputs.to(device),input_lengths.to(device),labels.to(device)\r\n",
    "        if inputs.shape[0] != batch_size:\r\n",
    "            continue\r\n",
    "        #print(f\"inputs.shape = {inputs.shape}, input_lengths = {input_lengths}, labels.shape = {labels.shape}\")\r\n",
    "        # forward pass on one mini batch\r\n",
    "        output, hidden = model(inputs, input_lengths, h)        \r\n",
    "        # compute the loss\r\n",
    "        loss = loss_fn(output.squeeze(), labels.float())\r\n",
    "        epoch_acc = accuracy(output, labels)\r\n",
    "        #print(f\"accuracy on training set batch {batch_count} = {epoch_acc.item()}\")\r\n",
    "        #print(f\"loss on training set batch {batch_count} = {loss.item()}\")\r\n",
    "        acc_epoch.append(epoch_acc.item())\r\n",
    "        loss_epoch.append(loss.item())\r\n",
    "        # zero out the model param gradients before running backprop\r\n",
    "        optimizer.zero_grad()\r\n",
    "        # run backprop to calculate param gradients (dW and db)\r\n",
    "        loss.backward()\r\n",
    "        # clip the param gradients if they exceed threshold\r\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\r\n",
    "        # update the parameters (W and b)\r\n",
    "        optimizer.step()\r\n",
    "        batch_count += 1\r\n",
    "    #print(loss_epoch)        \r\n",
    "    #print(epoch_acc)        \r\n",
    "    return np.mean(loss_epoch), np.mean(acc_epoch)  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "def val_epoch(dl, init_hidden, model, loss_fn, accuracy, device, batch_size):    \r\n",
    "    loss_epoch = []\r\n",
    "    acc_epoch = []\r\n",
    "    for inputs, input_lengths, labels in dl:\r\n",
    "        # create a new hidden state instance for each minibatch to avoid long gradient chains\r\n",
    "        # involving all previous minibatches of an epoch\r\n",
    "        h = tuple([e.data for e in init_hidden])\r\n",
    "        inputs,input_lengths,labels = inputs.to(device),input_lengths.to(device),labels.to(device)\r\n",
    "        if inputs.shape[0] != batch_size:\r\n",
    "            continue\r\n",
    "        # forward pass on one mini batch\r\n",
    "        output, hidden = model(inputs, input_lengths, h)\r\n",
    "        # compute the loss\r\n",
    "        loss = loss_fn(output.squeeze(), labels.float())\r\n",
    "        epoch_acc = accuracy(output, labels)\r\n",
    "        acc_epoch.append(epoch_acc.item())\r\n",
    "        loss_epoch.append(loss.item())                \r\n",
    "    return np.mean(loss_epoch), np.mean(acc_epoch)  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "def get_exec_time(exec_time_secs):\r\n",
    "    if exec_time_secs < 60:\r\n",
    "        return f\"{round(exec_time_secs, 2)} seconds\"\r\n",
    "    exec_time_rem_sec = exec_time_secs % 60\r\n",
    "    exec_time_min = int((exec_time_secs - exec_time_rem_sec) / 60)\r\n",
    "    return f\"{exec_time_min} min {round(exec_time_rem_sec, 2)} seconds\"\r\n",
    "\r\n",
    "def print_epoch_stats(epoch, val_loss_min, train_run_time, train_loss, \r\n",
    "                     train_acc, val_run_time, val_loss, val_acc):\r\n",
    "    print(f\"=======================================================\")\r\n",
    "    print(f\"Epoch {epoch} :\")\r\n",
    "    print(f\"Execution time on training set = {train_run_time} \")\r\n",
    "    print(f\"Training loss = {round(train_loss, 4)}, training accuracy = {round(train_acc, 4)}\")\r\n",
    "    print(f\"Execution time on validation set = {val_run_time} \")\r\n",
    "    print(f\"Validation loss = {round(val_loss, 4)}, validation accuracy = {round(val_acc, 4)}\")        \r\n",
    "    print(f\"=======================================================\")        \r\n",
    "    if val_loss < val_loss_min:        \r\n",
    "        print(f\"Validation loss decreased from \" +\r\n",
    "                f\"{round(val_loss_min, 6)} --> {round(val_loss, 6)}. Saving model...\")        \r\n",
    "        val_loss_min = val_loss                \r\n",
    "        torch.save(model, \"best_model.pt\")           \r\n",
    "    return val_loss_min        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "import time\r\n",
    "           \r\n",
    "def training_loop(train_dl, val_dl, model, loss_fn, optimizer, num_epochs, batch_size):\r\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "    torch.backends.cudnn.benchmark = True\r\n",
    "    model = model.to(device)\r\n",
    "    train_start_time = time.time()\r\n",
    "    val_loss_min = np.Inf\r\n",
    "    train_loss, val_loss = [], []    \r\n",
    "    train_acc, val_acc = [], []        \r\n",
    "    for epoch in range(num_epochs):\r\n",
    "        init_hidden = model.init_state(device = device, batch_size = batch_size)        \r\n",
    "        epoch_train_start_time = time.time()\r\n",
    "        model.train()\r\n",
    "        epoch_train_loss, epoch_train_acc = train_epoch(train_dl, init_hidden, model, loss_fn, \r\n",
    "                                                        optimizer, accuracy, device, batch_size)\r\n",
    "        #print(f\"Training loss = {epoch_train_loss}, training accuracy = {epoch_train_acc}\")                                                        \r\n",
    "        epoch_train_end_time = time.time()    \r\n",
    "        epoch_train_run_time = get_exec_time(epoch_train_end_time - epoch_train_start_time)\r\n",
    "        train_loss.append(epoch_train_loss)\r\n",
    "        train_acc.append(epoch_train_acc)\r\n",
    "        epoch_val_start_time = time.time()\r\n",
    "        model.eval()\r\n",
    "        epoch_val_loss, epoch_val_acc = val_epoch(val_dl, init_hidden, model, loss_fn, \r\n",
    "                                                  accuracy, device, batch_size)\r\n",
    "        epoch_val_end_time = time.time()\r\n",
    "        epoch_val_run_time = get_exec_time(epoch_val_end_time - epoch_val_start_time)\r\n",
    "        val_loss.append(epoch_val_loss)\r\n",
    "        val_acc.append(epoch_val_acc)                \r\n",
    "        val_loss_min = print_epoch_stats(epoch, val_loss_min, epoch_train_run_time, \r\n",
    "                                        epoch_train_loss, epoch_train_acc,\r\n",
    "                                        epoch_val_run_time, epoch_val_loss, epoch_val_acc)            \r\n",
    "    train_end_time = time.time()\r\n",
    "    train_run_time = get_exec_time(train_end_time - train_start_time)\r\n",
    "    print(f\"Training loop execution time for {num_epochs} epochs = {train_run_time}\")\r\n",
    "    return train_loss, train_acc, val_loss, val_acc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "source": [
    "# train_dl_iter = iter(train_dl)\r\n",
    "# inputs, input_lengths, labels = next(train_dl_iter)\r\n",
    "# print(inputs.shape, input_lengths.shape, labels.shape)\r\n",
    "# #print(inputs)\r\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "# init_hidden = model.init_state(device = device, batch_size = 64)\r\n",
    "# #print(init_hidden[0].shape, init_hidden[1].shape)\r\n",
    "# output, hidden = model(inputs, input_lengths, init_hidden)\r\n",
    "# print(f\"output.shape = {output.shape}\")\r\n",
    "# output = output.squeeze()\r\n",
    "# print(f\"After squeezing output.shape = {output.shape}\")\r\n",
    "# print(f\"Output = {output}\")\r\n",
    "# print(\"Labels:\")\r\n",
    "# print(labels.float())\r\n",
    "# loss = loss_fn(output.squeeze(), labels.float())\r\n",
    "# print(f\"loss = {loss}\")\r\n",
    "# acc = accuracy(output, labels)\r\n",
    "# print(f\"accuracy = {acc}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "def plot_train_val_metrics(ax, train_metric, val_metric, metric_name):\r\n",
    "    ax.plot(train_metric, label = f\"training {metric_name}\")\r\n",
    "    ax.plot(val_metric, label = f\"validation {metric_name}\")\r\n",
    "    ax.set_xlabel(\"epochs\")\r\n",
    "    ax.set_ylabel(metric_name)\r\n",
    "    ax.set_title(f\"{metric_name} vs epochs\")\r\n",
    "    ax.legend()\r\n",
    "    ax.grid()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "source": [
    "train_loss, train_acc, val_loss, val_acc = training_loop(\r\n",
    "                                            train_dl, val_dl, model, loss_fn, optimizer, \r\n",
    "                                            num_epochs=5, batch_size=batch_size\r\n",
    "                                            )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=======================================================\n",
      "Epoch 0 :\n",
      "Execution time on training set = 29.72 seconds \n",
      "Training loss = 0.4921, training accuracy = 0.7729\n",
      "Execution time on validation set = 1.51 seconds \n",
      "Validation loss = 0.4297, validation accuracy = 0.8132\n",
      "=======================================================\n",
      "Validation loss decreased from 0.429747 --> 0.429747. Saving model...\n",
      "=======================================================\n",
      "Epoch 1 :\n",
      "Execution time on training set = 26.21 seconds \n",
      "Training loss = 0.3723, training accuracy = 0.8469\n",
      "Execution time on validation set = 1.37 seconds \n",
      "Validation loss = 0.4532, validation accuracy = 0.8084\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 2 :\n",
      "Execution time on training set = 28.9 seconds \n",
      "Training loss = 0.2844, training accuracy = 0.889\n",
      "Execution time on validation set = 1.63 seconds \n",
      "Validation loss = 0.4866, validation accuracy = 0.8016\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 3 :\n",
      "Execution time on training set = 26.43 seconds \n",
      "Training loss = 0.192, training accuracy = 0.9242\n",
      "Execution time on validation set = 1.25 seconds \n",
      "Validation loss = 0.6643, validation accuracy = 0.7622\n",
      "=======================================================\n",
      "=======================================================\n",
      "Epoch 4 :\n",
      "Execution time on training set = 25.79 seconds \n",
      "Training loss = 0.123, training accuracy = 0.9536\n",
      "Execution time on validation set = 1.4 seconds \n",
      "Validation loss = 0.6919, validation accuracy = 0.7751\n",
      "=======================================================\n",
      "Training loop execution time for 5 epochs = 2 min 24.27 seconds\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\r\n",
    "plot_train_val_metrics(ax1, train_loss, val_loss, \"Loss\")\r\n",
    "plot_train_val_metrics(ax2, train_acc, val_acc, \"Accuracy\")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "source": [
    "best_model = torch.load(\"best_model.pt\")\r\n",
    "best_model"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DisasterModel(\n",
       "  (emb_layer): Embedding(14568, 200)\n",
       "  (lstm_layer): LSTM(200, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (act): Sigmoid()\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 133
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "source": [
    "df_test.head(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>prcsd_tweet_len</th>\n",
       "      <th>vectorized_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>happened terrible car crash</td>\n",
       "      <td>4</td>\n",
       "      <td>[tensor(758), tensor(1796), tensor(39), tensor(27)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, stay safe everyone.</td>\n",
       "      <td>heard earthquake different city stay safe everyone</td>\n",
       "      <td>7</td>\n",
       "      <td>[tensor(378), tensor(157), tensor(992), tensor(97), tensor(443), tensor(1592), tensor(137)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all</td>\n",
       "      <td>forest fire spot pond goose fleeing across street cannot save</td>\n",
       "      <td>10</td>\n",
       "      <td>[tensor(103), tensor(2), tensor(609), tensor(2837), tensor(0), tensor(4449), tensor(702), tensor(444), tensor(1195), tensor(257)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>apocalypse lighting spokane wildfire</td>\n",
       "      <td>4</td>\n",
       "      <td>[tensor(347), tensor(3441), tensor(13034), tensor(76)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>typhoon soudelor kill china taiwan</td>\n",
       "      <td>5</td>\n",
       "      <td>[tensor(132), tensor(560), tensor(104), tensor(247), tensor(1024)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We're shaking...It's an earthquake</td>\n",
       "      <td>shakingit earthquake</td>\n",
       "      <td>2</td>\n",
       "      <td>[tensor(0), tensor(157)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>NaN</td>\n",
       "      <td>They'd probably still show more life than Arsenal did yesterday, eh? EH?</td>\n",
       "      <td>probably still show life arsenal yesterday</td>\n",
       "      <td>6</td>\n",
       "      <td>[tensor(636), tensor(25), tensor(161), tensor(23), tensor(1830), tensor(1348)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hey! How are you?</td>\n",
       "      <td>hey</td>\n",
       "      <td>1</td>\n",
       "      <td>[tensor(575)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What a nice hat?</td>\n",
       "      <td>nice hat</td>\n",
       "      <td>2</td>\n",
       "      <td>[tensor(1082), tensor(573)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fuck off!</td>\n",
       "      <td>fuck</td>\n",
       "      <td>1</td>\n",
       "      <td>[tensor(279)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     keyword location  \\\n",
       "0   0  no_keyword      NaN   \n",
       "1   2  no_keyword      NaN   \n",
       "2   3  no_keyword      NaN   \n",
       "3   9  no_keyword      NaN   \n",
       "4  11  no_keyword      NaN   \n",
       "5  12  no_keyword      NaN   \n",
       "6  21  no_keyword      NaN   \n",
       "7  22  no_keyword      NaN   \n",
       "8  27  no_keyword      NaN   \n",
       "9  29  no_keyword      NaN   \n",
       "\n",
       "                                                                                               text  \\\n",
       "0                                                                Just happened a terrible car crash   \n",
       "1                                  Heard about #earthquake is different cities, stay safe everyone.   \n",
       "2  there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all   \n",
       "3                                                          Apocalypse lighting. #Spokane #wildfires   \n",
       "4                                                     Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "5                                                                We're shaking...It's an earthquake   \n",
       "6                          They'd probably still show more life than Arsenal did yesterday, eh? EH?   \n",
       "7                                                                                 Hey! How are you?   \n",
       "8                                                                                  What a nice hat?   \n",
       "9                                                                                         Fuck off!   \n",
       "\n",
       "                                                  processed_text  \\\n",
       "0                                    happened terrible car crash   \n",
       "1             heard earthquake different city stay safe everyone   \n",
       "2  forest fire spot pond goose fleeing across street cannot save   \n",
       "3                           apocalypse lighting spokane wildfire   \n",
       "4                             typhoon soudelor kill china taiwan   \n",
       "5                                           shakingit earthquake   \n",
       "6                     probably still show life arsenal yesterday   \n",
       "7                                                            hey   \n",
       "8                                                       nice hat   \n",
       "9                                                           fuck   \n",
       "\n",
       "   prcsd_tweet_len  \\\n",
       "0                4   \n",
       "1                7   \n",
       "2               10   \n",
       "3                4   \n",
       "4                5   \n",
       "5                2   \n",
       "6                6   \n",
       "7                1   \n",
       "8                2   \n",
       "9                1   \n",
       "\n",
       "                                                                                                                    vectorized_tweet  \n",
       "0                                                                                [tensor(758), tensor(1796), tensor(39), tensor(27)]  \n",
       "1                                        [tensor(378), tensor(157), tensor(992), tensor(97), tensor(443), tensor(1592), tensor(137)]  \n",
       "2  [tensor(103), tensor(2), tensor(609), tensor(2837), tensor(0), tensor(4449), tensor(702), tensor(444), tensor(1195), tensor(257)]  \n",
       "3                                                                             [tensor(347), tensor(3441), tensor(13034), tensor(76)]  \n",
       "4                                                                 [tensor(132), tensor(560), tensor(104), tensor(247), tensor(1024)]  \n",
       "5                                                                                                           [tensor(0), tensor(157)]  \n",
       "6                                                     [tensor(636), tensor(25), tensor(161), tensor(23), tensor(1830), tensor(1348)]  \n",
       "7                                                                                                                      [tensor(575)]  \n",
       "8                                                                                                        [tensor(1082), tensor(573)]  \n",
       "9                                                                                                                      [tensor(279)]  "
      ]
     },
     "metadata": {},
     "execution_count": 162
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "source": [
    "tweet_vocab.set_default_index(0)\r\n",
    "df_test[\"vectorized_tweet\"] = df_test[\"processed_text\"].apply(\r\n",
    "    lambda row:torch.LongTensor(tweet_vocab.lookup_indices(row.split()))\r\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "source": [
    "test_output = []\r\n",
    "for index, row in df_test.iterrows():    \r\n",
    "    vec_tweet = row[\"vectorized_tweet\"]\r\n",
    "    if len(vec_tweet) == 0:\r\n",
    "        test_output.append(0)\r\n",
    "        continue\r\n",
    "    vec_tweet_len = torch.IntTensor([len(vec_tweet)])\r\n",
    "    vec_tweet = vec_tweet.view(1, -1)    \r\n",
    "    #print(vec_tweet, vec_tweet_len)\r\n",
    "    output, (h_n,c_n) = best_model(vec_tweet, vec_tweet_len, state=None)\r\n",
    "    #print(output)\r\n",
    "    test_output.append(round(output.item()))    \r\n",
    "\r\n",
    "len(test_output)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3263"
      ]
     },
     "metadata": {},
     "execution_count": 169
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "source": [
    "test_output"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "metadata": {},
     "execution_count": 170
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "source": [
    "df_submission = pd.read_csv('./data/submission.csv')\r\n",
    "df_submission['target']= test_output\r\n",
    "df_submission.to_csv('my_submission2.csv',index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "source": [
    "val_dl_iter = iter(val_dl)\r\n",
    "input, input_len, label = next(val_dl_iter)\r\n",
    "input.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([64, 17])"
      ]
     },
     "metadata": {},
     "execution_count": 137
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "source": [
    "input = df_test[\"vectorized_tweet\"][1]\r\n",
    "input_len = len(input)\r\n",
    "input = input.view(1, -1)\r\n",
    "input_len = torch.IntTensor([input_len])\r\n",
    "input, input_len"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[ 378,  157,  992,   97,  443, 1592,  137]]),\n",
       " tensor([7], dtype=torch.int32))"
      ]
     },
     "metadata": {},
     "execution_count": 150
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "source": [
    "output, (h_n,c_n) = model(input, input_len, state=None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "source": [
    "output.item()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9378412365913391"
      ]
     },
     "metadata": {},
     "execution_count": 156
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('fastai': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 36.855353,
   "end_time": "2021-09-24T11:30:04.367162",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-24T11:29:27.511809",
   "version": "2.3.3"
  },
  "interpreter": {
   "hash": "2ff06204c0662b9359ef4233b0e8cfcc016e07736dbe455d1edaa8487878aae2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}